{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install pandas\n",
    "# !pip install sklearn\n",
    "# !pip install matplotlib\n",
    "# !pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.preprocessing import sequence\n",
    "from tensorflow.keras.layers import LSTM, GRU, Dense, Embedding, Dropout, Bidirectional\n",
    "from tensorflow.keras.models import Sequential\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.layers.recurrent import LSTM, SimpleRNN, GRU\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "\n",
    "tf.data.experimental.enable_debug_mode()\n",
    "tf.config.run_functions_eagerly(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>tweet</th>\n",
       "      <th>sarcastic</th>\n",
       "      <th>sarcasm</th>\n",
       "      <th>irony</th>\n",
       "      <th>satire</th>\n",
       "      <th>understatement</th>\n",
       "      <th>overstatement</th>\n",
       "      <th>rhetorical_question</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>The only thing I got from college is a caffein...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>I love it when professors draw a big question ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Remember the hundred emails from companies whe...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Today my pop-pop told me I was not “forced” to...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>@VolphanCarol @littlewhitty @mysticalmanatee I...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                              tweet  sarcastic  \\\n",
       "0           0  The only thing I got from college is a caffein...          1   \n",
       "1           1  I love it when professors draw a big question ...          1   \n",
       "2           2  Remember the hundred emails from companies whe...          1   \n",
       "3           3  Today my pop-pop told me I was not “forced” to...          1   \n",
       "4           4  @VolphanCarol @littlewhitty @mysticalmanatee I...          1   \n",
       "\n",
       "   sarcasm  irony  satire  understatement  overstatement  rhetorical_question  \n",
       "0      0.0    1.0     0.0             0.0            0.0                  0.0  \n",
       "1      1.0    0.0     0.0             0.0            0.0                  0.0  \n",
       "2      0.0    1.0     0.0             0.0            0.0                  0.0  \n",
       "3      1.0    0.0     0.0             0.0            0.0                  0.0  \n",
       "4      1.0    0.0     0.0             0.0            0.0                  0.0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets = pd.read_csv(\"sarcasm_dataset.csv\")\n",
    "\n",
    "tweets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>sarcastic</th>\n",
       "      <th>sarcasm</th>\n",
       "      <th>irony</th>\n",
       "      <th>satire</th>\n",
       "      <th>understatement</th>\n",
       "      <th>overstatement</th>\n",
       "      <th>rhetorical_question</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>862</th>\n",
       "      <td>yo @claires do yall do hysterectomies?</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>863</th>\n",
       "      <td>@JacobWohlReport Do I need to aquire a wife be...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>864</th>\n",
       "      <td>I get a lot of boy who cried wolf vibes from t...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>865</th>\n",
       "      <td>Update: holding hands with your mom and walkin...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>866</th>\n",
       "      <td>I might be rubbish at driving, and have a less...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 tweet  sarcastic  sarcasm  \\\n",
       "862             yo @claires do yall do hysterectomies?          1      1.0   \n",
       "863  @JacobWohlReport Do I need to aquire a wife be...          1      1.0   \n",
       "864  I get a lot of boy who cried wolf vibes from t...          1      0.0   \n",
       "865  Update: holding hands with your mom and walkin...          1      1.0   \n",
       "866  I might be rubbish at driving, and have a less...          1      1.0   \n",
       "\n",
       "     irony  satire  understatement  overstatement  rhetorical_question  \n",
       "862    0.0     0.0             0.0            0.0                  1.0  \n",
       "863    0.0     0.0             0.0            0.0                  1.0  \n",
       "864    1.0     0.0             0.0            0.0                  0.0  \n",
       "865    0.0     0.0             0.0            0.0                  0.0  \n",
       "866    0.0     0.0             0.0            0.0                  0.0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dop NaN columns\n",
    "tweets = tweets.drop(tweets.columns[0], axis=1)\n",
    "\n",
    "tweets.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Binary Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>sarcasm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The only thing I got from college is a caffein...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I love it when professors draw a big question ...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Remember the hundred emails from companies whe...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Today my pop-pop told me I was not “forced” to...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@VolphanCarol @littlewhitty @mysticalmanatee I...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               tweet  sarcasm\n",
       "0  The only thing I got from college is a caffein...      0.0\n",
       "1  I love it when professors draw a big question ...      1.0\n",
       "2  Remember the hundred emails from companies whe...      0.0\n",
       "3  Today my pop-pop told me I was not “forced” to...      1.0\n",
       "4  @VolphanCarol @littlewhitty @mysticalmanatee I...      1.0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dropping unnecessary columns for binary classification\n",
    "tweets1 = tweets.drop(['sarcasm', 'irony', 'satire', 'understatement', 'overstatement', 'rhetorical_question'], axis=1)\n",
    "tweets1.dropna(how='any', inplace=True)\n",
    "tweets1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert label from float to int\n",
    "def transform_float_to_int(value):\n",
    "    return int(value)\n",
    "\n",
    "tweets1['sarcastic'] = tweets1.sarcastic.apply(transform_float_to_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split Tweet and Sarcastic Column\n",
    "X = tweets1['tweet']\n",
    "y = tweets1['sarcastic']\n",
    "\n",
    "# Split Train & Test Data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=101, train_size=0.75)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_features = 20000\n",
    "EMBEDDING_DIM = 100\n",
    "VALIDATION_SPLIT = 0.25\n",
    "maxlen = 500\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vectorize the text samples into a 2D integer tensor\n",
    "tokenizer = Tokenizer(num_words=max_features)\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "sequences_train = tokenizer.texts_to_sequences(X_train)\n",
    "sequences_test = tokenizer.texts_to_sequences(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pad sequences (samples x time)\n",
      "X_train shape: (650, 500)\n",
      "X_test shape: (217, 500)\n"
     ]
    }
   ],
   "source": [
    "print('Pad sequences (samples x time)')\n",
    "X_train = sequence.pad_sequences(sequences_train, maxlen=maxlen)\n",
    "X_test = sequence.pad_sequences(sequences_test, maxlen=maxlen)\n",
    "\n",
    "\n",
    "print('X_train shape:', X_train.shape)\n",
    "print('X_test shape:', X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, None, 128)         2560000   \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 128)               131584    \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 128)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,691,713\n",
      "Trainable params: 2,691,713\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "21/21 [==============================] - 193s 9s/step - loss: 0.5668 - accuracy: 0.8154 - val_loss: 0.4871 - val_accuracy: 0.8249\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x227bb798550>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# LSTM Model with single layer and 0.2 dropout rate\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_features, 128))\n",
    "model.add(LSTM(128))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "model.build(X_train)\n",
    "print(model.summary())\n",
    "\n",
    "model.fit(X_train, y_train, batch_size=batch_size, epochs=1,\n",
    "          validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        38\n",
      "           1       0.82      1.00      0.90       179\n",
      "\n",
      "    accuracy                           0.82       217\n",
      "   macro avg       0.41      0.50      0.45       217\n",
      "weighted avg       0.68      0.82      0.75       217\n",
      "\n"
     ]
    }
   ],
   "source": [
    "preds = model.predict(X_test, verbose=0)\n",
    "predictions = [1 if x > 0.5 else 0 for x in preds]\n",
    "print(classification_report(y_test, predictions, zero_division=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_1 (Embedding)     (None, None, 128)         2560000   \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 128)               131584    \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,691,713\n",
      "Trainable params: 2,691,713\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "21/21 [==============================] - 149s 7s/step - loss: 0.5726 - accuracy: 0.8031 - val_loss: 0.4755 - val_accuracy: 0.8249\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x227bbb2fa90>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# LSTM Model with single layer and 0.4 dropout rate\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_features, 128))\n",
    "model.add(LSTM(128))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "model.build(X_train)\n",
    "print(model.summary())\n",
    "model.fit(X_train, y_train, batch_size=batch_size, epochs=1,\n",
    "          validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        38\n",
      "           1       0.82      1.00      0.90       179\n",
      "\n",
      "    accuracy                           0.82       217\n",
      "   macro avg       0.41      0.50      0.45       217\n",
      "weighted avg       0.68      0.82      0.75       217\n",
      "\n"
     ]
    }
   ],
   "source": [
    "preds = model.predict(X_test, verbose=0)\n",
    "predictions = [1 if x > 0.5 else 0 for x in preds]\n",
    "print(classification_report(y_test, predictions, zero_division=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_2 (Embedding)     (None, None, 128)         2560000   \n",
      "                                                                 \n",
      " lstm_2 (LSTM)               (None, 128)               131584    \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,691,713\n",
      "Trainable params: 2,691,713\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "21/21 [==============================] - 114s 5s/step - loss: 0.5894 - accuracy: 0.7923 - val_loss: 0.5128 - val_accuracy: 0.8249\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x227bc9be250>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# LSTM Model with single layer and 0.6 dropout rate\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_features, 128))\n",
    "model.add(LSTM(128))\n",
    "model.add(Dropout(0.6))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "model.build(X_train)\n",
    "print(model.summary())\n",
    "model.fit(X_train, y_train, batch_size=batch_size, epochs=1,\n",
    "          validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        38\n",
      "           1       0.82      1.00      0.90       179\n",
      "\n",
      "    accuracy                           0.82       217\n",
      "   macro avg       0.41      0.50      0.45       217\n",
      "weighted avg       0.68      0.82      0.75       217\n",
      "\n"
     ]
    }
   ],
   "source": [
    "preds = model.predict(X_test, verbose=0)\n",
    "predictions = [1 if x > 0.5 else 0 for x in preds]\n",
    "print(classification_report(y_test, predictions, zero_division=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_3 (Embedding)     (None, None, 128)         2560000   \n",
      "                                                                 \n",
      " lstm_3 (LSTM)               (None, 128)               131584    \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,691,713\n",
      "Trainable params: 2,691,713\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "21/21 [==============================] - 126s 6s/step - loss: 0.5853 - accuracy: 0.7969 - val_loss: 0.4679 - val_accuracy: 0.8249\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x227bca67730>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# LSTM Model with single layer and 0.8 dropout rate\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_features, 128))\n",
    "model.add(LSTM(128))\n",
    "model.add(Dropout(0.8))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "model.build(X_train)\n",
    "print(model.summary())\n",
    "model.fit(X_train, y_train, batch_size=batch_size, epochs=1,\n",
    "          validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        38\n",
      "           1       0.82      1.00      0.90       179\n",
      "\n",
      "    accuracy                           0.82       217\n",
      "   macro avg       0.41      0.50      0.45       217\n",
      "weighted avg       0.68      0.82      0.75       217\n",
      "\n"
     ]
    }
   ],
   "source": [
    "preds = model.predict(X_test, verbose=0)\n",
    "predictions = [1 if x > 0.5 else 0 for x in preds]\n",
    "print(classification_report(y_test, predictions, zero_division=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_4 (Embedding)     (None, None, 128)         2560000   \n",
      "                                                                 \n",
      " lstm_4 (LSTM)               (None, None, 128)         131584    \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, None, 128)         0         \n",
      "                                                                 \n",
      " lstm_5 (LSTM)               (None, 128)               131584    \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,823,297\n",
      "Trainable params: 2,823,297\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "21/21 [==============================] - 212s 10s/step - loss: 0.5405 - accuracy: 0.8077 - val_loss: 0.5007 - val_accuracy: 0.8249\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x227ce63af10>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# LSTM Model with Two layer and 0.2 dropout rate\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_features, 128))\n",
    "model.add(LSTM(128, return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(128))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "model.build(X_train)\n",
    "print(model.summary())\n",
    "model.fit(X_train, y_train, batch_size=batch_size, epochs=1,\n",
    "          validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        38\n",
      "           1       0.82      1.00      0.90       179\n",
      "\n",
      "    accuracy                           0.82       217\n",
      "   macro avg       0.41      0.50      0.45       217\n",
      "weighted avg       0.68      0.82      0.75       217\n",
      "\n"
     ]
    }
   ],
   "source": [
    "preds = model.predict(X_test, verbose=0)\n",
    "predictions = [1 if x > 0.5 else 0 for x in preds]\n",
    "print(classification_report(y_test, predictions, zero_division=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_5 (Embedding)     (None, None, 128)         2560000   \n",
      "                                                                 \n",
      " lstm_6 (LSTM)               (None, None, 128)         131584    \n",
      "                                                                 \n",
      " dropout_6 (Dropout)         (None, None, 128)         0         \n",
      "                                                                 \n",
      " lstm_7 (LSTM)               (None, 128)               131584    \n",
      "                                                                 \n",
      " dropout_7 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,823,297\n",
      "Trainable params: 2,823,297\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "21/21 [==============================] - 310s 15s/step - loss: 0.5331 - accuracy: 0.8154 - val_loss: 0.4680 - val_accuracy: 0.8249\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x227cb51a700>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# LSTM Model with Two layer and 0.4 dropout rate\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_features, 128))\n",
    "model.add(LSTM(128, return_sequences=True))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(LSTM(128))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "model.build(X_train)\n",
    "print(model.summary())\n",
    "model.fit(X_train, y_train, batch_size=batch_size, epochs=1,\n",
    "          validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        38\n",
      "           1       0.82      1.00      0.90       179\n",
      "\n",
      "    accuracy                           0.82       217\n",
      "   macro avg       0.41      0.50      0.45       217\n",
      "weighted avg       0.68      0.82      0.75       217\n",
      "\n"
     ]
    }
   ],
   "source": [
    "preds = model.predict(X_test, verbose=0)\n",
    "predictions = [1 if x > 0.5 else 0 for x in preds]\n",
    "print(classification_report(y_test, predictions, zero_division=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_6 (Embedding)     (None, None, 128)         2560000   \n",
      "                                                                 \n",
      " lstm_8 (LSTM)               (None, None, 128)         131584    \n",
      "                                                                 \n",
      " dropout_8 (Dropout)         (None, None, 128)         0         \n",
      "                                                                 \n",
      " lstm_9 (LSTM)               (None, 128)               131584    \n",
      "                                                                 \n",
      " dropout_9 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,823,297\n",
      "Trainable params: 2,823,297\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "21/21 [==============================] - 293s 14s/step - loss: 0.5484 - accuracy: 0.8077 - val_loss: 0.4690 - val_accuracy: 0.8249\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x227c53ed430>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# LSTM Model with Two layer and 0.6 dropout rate\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_features, 128))\n",
    "model.add(LSTM(128, return_sequences=True))\n",
    "model.add(Dropout(0.6))\n",
    "model.add(LSTM(128))\n",
    "model.add(Dropout(0.6))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "model.build(X_train)\n",
    "print(model.summary())\n",
    "model.fit(X_train, y_train, batch_size=batch_size, epochs=1,\n",
    "          validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        38\n",
      "           1       0.82      1.00      0.90       179\n",
      "\n",
      "    accuracy                           0.82       217\n",
      "   macro avg       0.41      0.50      0.45       217\n",
      "weighted avg       0.68      0.82      0.75       217\n",
      "\n"
     ]
    }
   ],
   "source": [
    "preds = model.predict(X_test, verbose=0)\n",
    "predictions = [1 if x > 0.5 else 0 for x in preds]\n",
    "print(classification_report(y_test, predictions, zero_division=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_7 (Embedding)     (None, None, 128)         2560000   \n",
      "                                                                 \n",
      " lstm_10 (LSTM)              (None, None, 128)         131584    \n",
      "                                                                 \n",
      " dropout_10 (Dropout)        (None, None, 128)         0         \n",
      "                                                                 \n",
      " lstm_11 (LSTM)              (None, 128)               131584    \n",
      "                                                                 \n",
      " dropout_11 (Dropout)        (None, 128)               0         \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,823,297\n",
      "Trainable params: 2,823,297\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "21/21 [==============================] - 300s 14s/step - loss: 0.5740 - accuracy: 0.8015 - val_loss: 0.4888 - val_accuracy: 0.8249\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x227c74680a0>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# LSTM Model with Two layer and 0.8 dropout rate\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_features, 128))\n",
    "model.add(LSTM(128, return_sequences=True))\n",
    "model.add(Dropout(0.8))\n",
    "model.add(LSTM(128))\n",
    "model.add(Dropout(0.8))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "model.build(X_train)\n",
    "print(model.summary())\n",
    "model.fit(X_train, y_train, batch_size=batch_size, epochs=1,\n",
    "          validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        38\n",
      "           1       0.82      1.00      0.90       179\n",
      "\n",
      "    accuracy                           0.82       217\n",
      "   macro avg       0.41      0.50      0.45       217\n",
      "weighted avg       0.68      0.82      0.75       217\n",
      "\n"
     ]
    }
   ],
   "source": [
    "preds = model.predict(X_test, verbose=0)\n",
    "predictions = [1 if x > 0.5 else 0 for x in preds]\n",
    "print(classification_report(y_test, predictions, zero_division=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_8 (Embedding)     (None, None, 128)         2560000   \n",
      "                                                                 \n",
      " lstm_12 (LSTM)              (None, None, 128)         131584    \n",
      "                                                                 \n",
      " dropout_12 (Dropout)        (None, None, 128)         0         \n",
      "                                                                 \n",
      " lstm_13 (LSTM)              (None, None, 128)         131584    \n",
      "                                                                 \n",
      " dropout_13 (Dropout)        (None, None, 128)         0         \n",
      "                                                                 \n",
      " lstm_14 (LSTM)              (None, 128)               131584    \n",
      "                                                                 \n",
      " dropout_14 (Dropout)        (None, 128)               0         \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,954,881\n",
      "Trainable params: 2,954,881\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "21/21 [==============================] - 381s 18s/step - loss: 0.5317 - accuracy: 0.7923 - val_loss: 0.4828 - val_accuracy: 0.8249\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x227bbabf460>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# LSTM Model with Three layer and 0.2 dropout rate\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_features, 128))\n",
    "model.add(LSTM(128, return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(128, return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(128))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "model.build(X_train)\n",
    "print(model.summary())\n",
    "model.fit(X_train, y_train, batch_size=batch_size, epochs=1,\n",
    "          validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        38\n",
      "           1       0.82      1.00      0.90       179\n",
      "\n",
      "    accuracy                           0.82       217\n",
      "   macro avg       0.41      0.50      0.45       217\n",
      "weighted avg       0.68      0.82      0.75       217\n",
      "\n"
     ]
    }
   ],
   "source": [
    "preds = model.predict(X_test, verbose=0)\n",
    "predictions = [1 if x > 0.5 else 0 for x in preds]\n",
    "print(classification_report(y_test, predictions, zero_division=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_9 (Embedding)     (None, None, 128)         2560000   \n",
      "                                                                 \n",
      " lstm_15 (LSTM)              (None, None, 128)         131584    \n",
      "                                                                 \n",
      " dropout_15 (Dropout)        (None, None, 128)         0         \n",
      "                                                                 \n",
      " lstm_16 (LSTM)              (None, None, 128)         131584    \n",
      "                                                                 \n",
      " dropout_16 (Dropout)        (None, None, 128)         0         \n",
      "                                                                 \n",
      " lstm_17 (LSTM)              (None, 128)               131584    \n",
      "                                                                 \n",
      " dropout_17 (Dropout)        (None, 128)               0         \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,954,881\n",
      "Trainable params: 2,954,881\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "21/21 [==============================] - 354s 17s/step - loss: 0.5450 - accuracy: 0.8154 - val_loss: 0.4694 - val_accuracy: 0.8249\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x227c7460850>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# LSTM Model with Three layer and 0.4 dropout rate\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_features, 128))\n",
    "model.add(LSTM(128, return_sequences=True))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(LSTM(128, return_sequences=True))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(LSTM(128))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "model.build(X_train)\n",
    "print(model.summary())\n",
    "model.fit(X_train, y_train, batch_size=batch_size, epochs=1,\n",
    "          validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        38\n",
      "           1       0.82      1.00      0.90       179\n",
      "\n",
      "    accuracy                           0.82       217\n",
      "   macro avg       0.41      0.50      0.45       217\n",
      "weighted avg       0.68      0.82      0.75       217\n",
      "\n"
     ]
    }
   ],
   "source": [
    "preds = model.predict(X_test, verbose=0)\n",
    "predictions = [1 if x > 0.5 else 0 for x in preds]\n",
    "print(classification_report(y_test, predictions, zero_division=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_10 (Embedding)    (None, None, 128)         2560000   \n",
      "                                                                 \n",
      " lstm_18 (LSTM)              (None, None, 128)         131584    \n",
      "                                                                 \n",
      " dropout_18 (Dropout)        (None, None, 128)         0         \n",
      "                                                                 \n",
      " lstm_19 (LSTM)              (None, None, 128)         131584    \n",
      "                                                                 \n",
      " dropout_19 (Dropout)        (None, None, 128)         0         \n",
      "                                                                 \n",
      " lstm_20 (LSTM)              (None, 128)               131584    \n",
      "                                                                 \n",
      " dropout_20 (Dropout)        (None, 128)               0         \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,954,881\n",
      "Trainable params: 2,954,881\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "21/21 [==============================] - 417s 20s/step - loss: 0.5336 - accuracy: 0.8138 - val_loss: 0.4674 - val_accuracy: 0.8249\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x227ea830640>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# LSTM Model with Three layer and 0.6 dropout rate\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_features, 128))\n",
    "model.add(LSTM(128, return_sequences=True))\n",
    "model.add(Dropout(0.6))\n",
    "model.add(LSTM(128, return_sequences=True))\n",
    "model.add(Dropout(0.6))\n",
    "model.add(LSTM(128))\n",
    "model.add(Dropout(0.6))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "model.build(X_train)\n",
    "print(model.summary())\n",
    "model.fit(X_train, y_train, batch_size=batch_size, epochs=1,\n",
    "          validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        38\n",
      "           1       0.82      1.00      0.90       179\n",
      "\n",
      "    accuracy                           0.82       217\n",
      "   macro avg       0.41      0.50      0.45       217\n",
      "weighted avg       0.68      0.82      0.75       217\n",
      "\n"
     ]
    }
   ],
   "source": [
    "preds = model.predict(X_test, verbose=0)\n",
    "predictions = [1 if x > 0.5 else 0 for x in preds]\n",
    "print(classification_report(y_test, predictions, zero_division=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_11\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_11 (Embedding)    (None, None, 128)         2560000   \n",
      "                                                                 \n",
      " lstm_21 (LSTM)              (None, None, 128)         131584    \n",
      "                                                                 \n",
      " dropout_21 (Dropout)        (None, None, 128)         0         \n",
      "                                                                 \n",
      " lstm_22 (LSTM)              (None, None, 128)         131584    \n",
      "                                                                 \n",
      " dropout_22 (Dropout)        (None, None, 128)         0         \n",
      "                                                                 \n",
      " lstm_23 (LSTM)              (None, 128)               131584    \n",
      "                                                                 \n",
      " dropout_23 (Dropout)        (None, 128)               0         \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,954,881\n",
      "Trainable params: 2,954,881\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "21/21 [==============================] - 348s 17s/step - loss: 0.5523 - accuracy: 0.7954 - val_loss: 0.4681 - val_accuracy: 0.8249\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x227bc0c0cd0>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# LSTM Model with Three layer and 0.8 dropout rate\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_features, 128))\n",
    "model.add(LSTM(128, return_sequences=True))\n",
    "model.add(Dropout(0.8))\n",
    "model.add(LSTM(128, return_sequences=True))\n",
    "model.add(Dropout(0.8))\n",
    "model.add(LSTM(128))\n",
    "model.add(Dropout(0.8))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "model.build(X_train)\n",
    "print(model.summary())\n",
    "model.fit(X_train, y_train, batch_size=batch_size, epochs=1,\n",
    "          validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model.predict(X_test, verbose=0)\n",
    "predictions = [1 if x > 0.5 else 0 for x in preds]\n",
    "print(classification_report(y_test, predictions, zero_division=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BiLSTM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BiLSTM Model with single layer and 0.2 dropout rate\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_features, 128))\n",
    "model.add(Bidirectional(LSTM(128)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "model.build(X_train)\n",
    "print(model.summary())\n",
    "\n",
    "model.fit(X_train, y_train, batch_size=batch_size, epochs=1,\n",
    "          validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model.predict(X_test, verbose=0)\n",
    "predictions = [1 if x > 0.5 else 0 for x in preds]\n",
    "print(classification_report(y_test, predictions, zero_division=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BiLSTM Model with single layer and 0.4 dropout rate\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_features, 128))\n",
    "model.add(Bidirectional(LSTM(128)))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "model.build(X_train)\n",
    "print(model.summary())\n",
    "\n",
    "model.fit(X_train, y_train, batch_size=batch_size, epochs=1,\n",
    "          validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model.predict(X_test, verbose=0)\n",
    "predictions = [1 if x > 0.5 else 0 for x in preds]\n",
    "print(classification_report(y_test, predictions, zero_division=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BiLSTM Model with single layer and 0.6 dropout rate\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_features, 128))\n",
    "model.add(Bidirectional(LSTM(128)))\n",
    "model.add(Dropout(0.6))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "model.build(X_train)\n",
    "print(model.summary())\n",
    "\n",
    "model.fit(X_train, y_train, batch_size=batch_size, epochs=1,\n",
    "          validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model.predict(X_test, verbose=0)\n",
    "predictions = [1 if x > 0.5 else 0 for x in preds]\n",
    "print(classification_report(y_test, predictions, zero_division=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BiLSTM Model with single layer and 0.8 dropout rate\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_features, 128))\n",
    "model.add(Bidirectional(LSTM(128)))\n",
    "model.add(Dropout(0.8))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "model.build(X_train)\n",
    "print(model.summary())\n",
    "\n",
    "model.fit(X_train, y_train, batch_size=batch_size, epochs=1,\n",
    "          validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model.predict(X_test, verbose=0)\n",
    "predictions = [1 if x > 0.5 else 0 for x in preds]\n",
    "print(classification_report(y_test, predictions, zero_division=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BiLSTM Model with Two layer and 0.2 dropout rate\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_features, 128))\n",
    "model.add(Bidirectional(LSTM(128, return_sequences=True)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Bidirectional(LSTM(128)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "model.build(X_train)\n",
    "print(model.summary())\n",
    "\n",
    "model.fit(X_train, y_train, batch_size=batch_size, epochs=1,\n",
    "          validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model.predict(X_test, verbose=0)\n",
    "predictions = [1 if x > 0.5 else 0 for x in preds]\n",
    "print(classification_report(y_test, predictions, zero_division=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BiLSTM Model with Two layer and 0.4 dropout rate\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_features, 128))\n",
    "model.add(Bidirectional(LSTM(128, return_sequences=True)))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Bidirectional(LSTM(128)))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "model.build(X_train)\n",
    "print(model.summary())\n",
    "\n",
    "model.fit(X_train, y_train, batch_size=batch_size, epochs=1,\n",
    "          validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model.predict(X_test, verbose=0)\n",
    "predictions = [1 if x > 0.5 else 0 for x in preds]\n",
    "print(classification_report(y_test, predictions, zero_division=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BiLSTM Model with Two layer and 0.6 dropout rate\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_features, 128))\n",
    "model.add(Bidirectional(LSTM(128, return_sequences=True)))\n",
    "model.add(Dropout(0.6))\n",
    "model.add(Bidirectional(LSTM(128)))\n",
    "model.add(Dropout(0.6))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "model.build(X_train)\n",
    "print(model.summary())\n",
    "\n",
    "model.fit(X_train, y_train, batch_size=batch_size, epochs=1,\n",
    "          validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model.predict(X_test, verbose=0)\n",
    "predictions = [1 if x > 0.5 else 0 for x in preds]\n",
    "print(classification_report(y_test, predictions, zero_division=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BiLSTM Model with Two layer and 0.8 dropout rate\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_features, 128))\n",
    "model.add(Bidirectional(LSTM(128, return_sequences=True)))\n",
    "model.add(Dropout(0.8))\n",
    "model.add(Bidirectional(LSTM(128)))\n",
    "model.add(Dropout(0.8))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "model.build(X_train)\n",
    "print(model.summary())\n",
    "\n",
    "model.fit(X_train, y_train, batch_size=batch_size, epochs=1,\n",
    "          validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model.predict(X_test, verbose=0)\n",
    "predictions = [1 if x > 0.5 else 0 for x in preds]\n",
    "print(classification_report(y_test, predictions, zero_division=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BiLSTM Model with Three layer and 0.2 dropout rate\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_features, 128))\n",
    "model.add(Bidirectional(LSTM(128, return_sequences=True)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Bidirectional(LSTM(128, return_sequences=True)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Bidirectional(LSTM(128)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "model.build(X_train)\n",
    "print(model.summary())\n",
    "\n",
    "model.fit(X_train, y_train, batch_size=batch_size, epochs=1,\n",
    "          validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model.predict(X_test, verbose=0)\n",
    "predictions = [1 if x > 0.5 else 0 for x in preds]\n",
    "print(classification_report(y_test, predictions, zero_division=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BiLSTM Model with Three layer and 0.4 dropout rate\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_features, 128))\n",
    "model.add(Bidirectional(LSTM(128, return_sequences=True)))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Bidirectional(LSTM(128, return_sequences=True)))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Bidirectional(LSTM(128)))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "model.build(X_train)\n",
    "print(model.summary())\n",
    "\n",
    "model.fit(X_train, y_train, batch_size=batch_size, epochs=1,\n",
    "          validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model.predict(X_test, verbose=0)\n",
    "predictions = [1 if x > 0.5 else 0 for x in preds]\n",
    "print(classification_report(y_test, predictions, zero_division=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BiLSTM Model with Three layer and 0.6 dropout rate\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_features, 128))\n",
    "model.add(Bidirectional(LSTM(128, return_sequences=True)))\n",
    "model.add(Dropout(0.6))\n",
    "model.add(Bidirectional(LSTM(128, return_sequences=True)))\n",
    "model.add(Dropout(0.6))\n",
    "model.add(Bidirectional(LSTM(128)))\n",
    "model.add(Dropout(0.6))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "model.build(X_train)\n",
    "print(model.summary())\n",
    "\n",
    "model.fit(X_train, y_train, batch_size=batch_size, epochs=1,\n",
    "          validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model.predict(X_test, verbose=0)\n",
    "predictions = [1 if x > 0.5 else 0 for x in preds]\n",
    "print(classification_report(y_test, predictions, zero_division=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BiLSTM Model with Three layer and 0.8 dropout rate\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_features, 128))\n",
    "model.add(Bidirectional(LSTM(128, return_sequences=True)))\n",
    "model.add(Dropout(0.8))\n",
    "model.add(Bidirectional(LSTM(128, return_sequences=True)))\n",
    "model.add(Dropout(0.8))\n",
    "model.add(Bidirectional(LSTM(128)))\n",
    "model.add(Dropout(0.8))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "model.build(X_train)\n",
    "print(model.summary())\n",
    "\n",
    "model.fit(X_train, y_train, batch_size=batch_size, epochs=1,\n",
    "          validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model.predict(X_test, verbose=0)\n",
    "predictions = [1 if x > 0.5 else 0 for x in preds]\n",
    "print(classification_report(y_test, predictions, zero_division=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_12\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_12 (Embedding)    (None, None, 128)         2560000   \n",
      "                                                                 \n",
      " simple_rnn (SimpleRNN)      (None, 128)               32896     \n",
      "                                                                 \n",
      " dropout_24 (Dropout)        (None, 128)               0         \n",
      "                                                                 \n",
      " dense_12 (Dense)            (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,593,025\n",
      "Trainable params: 2,593,025\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "21/21 [==============================] - 16s 777ms/step - loss: 0.4901 - accuracy: 0.8169 - val_loss: 0.4640 - val_accuracy: 0.8249\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x227ce5c27f0>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# RNN Model with single layer and 0.2 dropout rate\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_features, 128))\n",
    "model.add(SimpleRNN(128))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "model.build(X_train)\n",
    "print(model.summary())\n",
    "\n",
    "model.fit(X_train, y_train, batch_size=batch_size, epochs=1,\n",
    "          validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        38\n",
      "           1       0.82      1.00      0.90       179\n",
      "\n",
      "    accuracy                           0.82       217\n",
      "   macro avg       0.41      0.50      0.45       217\n",
      "weighted avg       0.68      0.82      0.75       217\n",
      "\n"
     ]
    }
   ],
   "source": [
    "preds = model.predict(X_test, verbose=0)\n",
    "predictions = [1 if x > 0.5 else 0 for x in preds]\n",
    "print(classification_report(y_test, predictions, zero_division=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_13\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_13 (Embedding)    (None, None, 128)         2560000   \n",
      "                                                                 \n",
      " simple_rnn_1 (SimpleRNN)    (None, 128)               32896     \n",
      "                                                                 \n",
      " dropout_25 (Dropout)        (None, 128)               0         \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,593,025\n",
      "Trainable params: 2,593,025\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "21/21 [==============================] - 16s 785ms/step - loss: 0.5033 - accuracy: 0.8108 - val_loss: 0.4667 - val_accuracy: 0.8249\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x227ea71d940>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# RNN Model with single layer and 0.4 dropout rate\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_features, 128))\n",
    "model.add(SimpleRNN(128))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "model.build(X_train)\n",
    "print(model.summary())\n",
    "\n",
    "model.fit(X_train, y_train, batch_size=batch_size, epochs=1,\n",
    "          validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        38\n",
      "           1       0.82      1.00      0.90       179\n",
      "\n",
      "    accuracy                           0.82       217\n",
      "   macro avg       0.41      0.50      0.45       217\n",
      "weighted avg       0.68      0.82      0.75       217\n",
      "\n"
     ]
    }
   ],
   "source": [
    "preds = model.predict(X_test, verbose=0)\n",
    "predictions = [1 if x > 0.5 else 0 for x in preds]\n",
    "print(classification_report(y_test, predictions, zero_division=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_14\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_14 (Embedding)    (None, None, 128)         2560000   \n",
      "                                                                 \n",
      " simple_rnn_2 (SimpleRNN)    (None, 128)               32896     \n",
      "                                                                 \n",
      " dropout_26 (Dropout)        (None, 128)               0         \n",
      "                                                                 \n",
      " dense_14 (Dense)            (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,593,025\n",
      "Trainable params: 2,593,025\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "21/21 [==============================] - 16s 772ms/step - loss: 0.5078 - accuracy: 0.8000 - val_loss: 0.4646 - val_accuracy: 0.8249\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x227cc5d2640>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# RNN Model with single layer and 0.6 dropout rate\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_features, 128))\n",
    "model.add(SimpleRNN(128))\n",
    "model.add(Dropout(0.6))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "model.build(X_train)\n",
    "print(model.summary())\n",
    "\n",
    "model.fit(X_train, y_train, batch_size=batch_size, epochs=1,\n",
    "          validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        38\n",
      "           1       0.82      1.00      0.90       179\n",
      "\n",
      "    accuracy                           0.82       217\n",
      "   macro avg       0.41      0.50      0.45       217\n",
      "weighted avg       0.68      0.82      0.75       217\n",
      "\n"
     ]
    }
   ],
   "source": [
    "preds = model.predict(X_test, verbose=0)\n",
    "predictions = [1 if x > 0.5 else 0 for x in preds]\n",
    "print(classification_report(y_test, predictions, zero_division=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_15\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_15 (Embedding)    (None, None, 128)         2560000   \n",
      "                                                                 \n",
      " simple_rnn_3 (SimpleRNN)    (None, 128)               32896     \n",
      "                                                                 \n",
      " dropout_27 (Dropout)        (None, 128)               0         \n",
      "                                                                 \n",
      " dense_15 (Dense)            (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,593,025\n",
      "Trainable params: 2,593,025\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "21/21 [==============================] - 16s 773ms/step - loss: 0.5904 - accuracy: 0.7446 - val_loss: 0.5264 - val_accuracy: 0.8249\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x227cc5cf640>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# RNN Model with single layer and 0.8 dropout rate\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_features, 128))\n",
    "model.add(SimpleRNN(128))\n",
    "model.add(Dropout(0.8))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "model.build(X_train)\n",
    "print(model.summary())\n",
    "\n",
    "model.fit(X_train, y_train, batch_size=batch_size, epochs=1,\n",
    "          validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        38\n",
      "           1       0.82      1.00      0.90       179\n",
      "\n",
      "    accuracy                           0.82       217\n",
      "   macro avg       0.41      0.50      0.45       217\n",
      "weighted avg       0.68      0.82      0.75       217\n",
      "\n"
     ]
    }
   ],
   "source": [
    "preds = model.predict(X_test, verbose=0)\n",
    "predictions = [1 if x > 0.5 else 0 for x in preds]\n",
    "print(classification_report(y_test, predictions, zero_division=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_16\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_16 (Embedding)    (None, None, 128)         2560000   \n",
      "                                                                 \n",
      " simple_rnn_4 (SimpleRNN)    (None, None, 128)         32896     \n",
      "                                                                 \n",
      " dropout_28 (Dropout)        (None, None, 128)         0         \n",
      "                                                                 \n",
      " simple_rnn_5 (SimpleRNN)    (None, 128)               32896     \n",
      "                                                                 \n",
      " dropout_29 (Dropout)        (None, 128)               0         \n",
      "                                                                 \n",
      " dense_16 (Dense)            (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,625,921\n",
      "Trainable params: 2,625,921\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "21/21 [==============================] - 34s 2s/step - loss: 0.5250 - accuracy: 0.7954 - val_loss: 0.4900 - val_accuracy: 0.8249\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x227bba49310>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# RNN Model with Two layer and 0.2 dropout rate\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_features, 128))\n",
    "model.add(SimpleRNN(128, return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(SimpleRNN(128))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "model.build(X_train)\n",
    "print(model.summary())\n",
    "\n",
    "model.fit(X_train, y_train, batch_size=batch_size, epochs=1,\n",
    "          validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        38\n",
      "           1       0.82      1.00      0.90       179\n",
      "\n",
      "    accuracy                           0.82       217\n",
      "   macro avg       0.41      0.50      0.45       217\n",
      "weighted avg       0.68      0.82      0.75       217\n",
      "\n"
     ]
    }
   ],
   "source": [
    "preds = model.predict(X_test, verbose=0)\n",
    "predictions = [1 if x > 0.5 else 0 for x in preds]\n",
    "print(classification_report(y_test, predictions, zero_division=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_17\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_17 (Embedding)    (None, None, 128)         2560000   \n",
      "                                                                 \n",
      " simple_rnn_6 (SimpleRNN)    (None, None, 128)         32896     \n",
      "                                                                 \n",
      " dropout_30 (Dropout)        (None, None, 128)         0         \n",
      "                                                                 \n",
      " simple_rnn_7 (SimpleRNN)    (None, 128)               32896     \n",
      "                                                                 \n",
      " dropout_31 (Dropout)        (None, 128)               0         \n",
      "                                                                 \n",
      " dense_17 (Dense)            (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,625,921\n",
      "Trainable params: 2,625,921\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "21/21 [==============================] - 33s 2s/step - loss: 0.5340 - accuracy: 0.7800 - val_loss: 0.4691 - val_accuracy: 0.8249\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x227e1737a90>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# RNN Model with Two layer and 0.4 dropout rate\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_features, 128))\n",
    "model.add(SimpleRNN(128, return_sequences=True))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(SimpleRNN(128))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "model.build(X_train)\n",
    "print(model.summary())\n",
    "\n",
    "model.fit(X_train, y_train, batch_size=batch_size, epochs=1,\n",
    "          validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        38\n",
      "           1       0.82      1.00      0.90       179\n",
      "\n",
      "    accuracy                           0.82       217\n",
      "   macro avg       0.41      0.50      0.45       217\n",
      "weighted avg       0.68      0.82      0.75       217\n",
      "\n"
     ]
    }
   ],
   "source": [
    "preds = model.predict(X_test, verbose=0)\n",
    "predictions = [1 if x > 0.5 else 0 for x in preds]\n",
    "print(classification_report(y_test, predictions, zero_division=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_18\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_18 (Embedding)    (None, None, 128)         2560000   \n",
      "                                                                 \n",
      " simple_rnn_8 (SimpleRNN)    (None, None, 128)         32896     \n",
      "                                                                 \n",
      " dropout_32 (Dropout)        (None, None, 128)         0         \n",
      "                                                                 \n",
      " simple_rnn_9 (SimpleRNN)    (None, 128)               32896     \n",
      "                                                                 \n",
      " dropout_33 (Dropout)        (None, 128)               0         \n",
      "                                                                 \n",
      " dense_18 (Dense)            (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,625,921\n",
      "Trainable params: 2,625,921\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "21/21 [==============================] - 33s 2s/step - loss: 0.5887 - accuracy: 0.7354 - val_loss: 0.4800 - val_accuracy: 0.8249\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x227e18fc640>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# RNN Model with Two layer and 0.6 dropout rate\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_features, 128))\n",
    "model.add(SimpleRNN(128, return_sequences=True))\n",
    "model.add(Dropout(0.6))\n",
    "model.add(SimpleRNN(128))\n",
    "model.add(Dropout(0.6))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "model.build(X_train)\n",
    "print(model.summary())\n",
    "\n",
    "model.fit(X_train, y_train, batch_size=batch_size, epochs=1,\n",
    "          validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        38\n",
      "           1       0.82      1.00      0.90       179\n",
      "\n",
      "    accuracy                           0.82       217\n",
      "   macro avg       0.41      0.50      0.45       217\n",
      "weighted avg       0.68      0.82      0.75       217\n",
      "\n"
     ]
    }
   ],
   "source": [
    "preds = model.predict(X_test, verbose=0)\n",
    "predictions = [1 if x > 0.5 else 0 for x in preds]\n",
    "print(classification_report(y_test, predictions, zero_division=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_19\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_19 (Embedding)    (None, None, 128)         2560000   \n",
      "                                                                 \n",
      " simple_rnn_10 (SimpleRNN)   (None, None, 128)         32896     \n",
      "                                                                 \n",
      " dropout_34 (Dropout)        (None, None, 128)         0         \n",
      "                                                                 \n",
      " simple_rnn_11 (SimpleRNN)   (None, 128)               32896     \n",
      "                                                                 \n",
      " dropout_35 (Dropout)        (None, 128)               0         \n",
      "                                                                 \n",
      " dense_19 (Dense)            (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,625,921\n",
      "Trainable params: 2,625,921\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "21/21 [==============================] - 33s 2s/step - loss: 0.6862 - accuracy: 0.6985 - val_loss: 0.5688 - val_accuracy: 0.8249\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x227bc7320a0>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# RNN Model with Two layer and 0.8 dropout rate\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_features, 128))\n",
    "model.add(SimpleRNN(128, return_sequences=True))\n",
    "model.add(Dropout(0.8))\n",
    "model.add(SimpleRNN(128))\n",
    "model.add(Dropout(0.8))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "model.build(X_train)\n",
    "print(model.summary())\n",
    "\n",
    "model.fit(X_train, y_train, batch_size=batch_size, epochs=1,\n",
    "          validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        38\n",
      "           1       0.82      1.00      0.90       179\n",
      "\n",
      "    accuracy                           0.82       217\n",
      "   macro avg       0.41      0.50      0.45       217\n",
      "weighted avg       0.68      0.82      0.75       217\n",
      "\n"
     ]
    }
   ],
   "source": [
    "preds = model.predict(X_test, verbose=0)\n",
    "predictions = [1 if x > 0.5 else 0 for x in preds]\n",
    "print(classification_report(y_test, predictions, zero_division=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_20\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_20 (Embedding)    (None, None, 128)         2560000   \n",
      "                                                                 \n",
      " simple_rnn_12 (SimpleRNN)   (None, None, 128)         32896     \n",
      "                                                                 \n",
      " dropout_36 (Dropout)        (None, None, 128)         0         \n",
      "                                                                 \n",
      " simple_rnn_13 (SimpleRNN)   (None, None, 128)         32896     \n",
      "                                                                 \n",
      " dropout_37 (Dropout)        (None, None, 128)         0         \n",
      "                                                                 \n",
      " simple_rnn_14 (SimpleRNN)   (None, 128)               32896     \n",
      "                                                                 \n",
      " dropout_38 (Dropout)        (None, 128)               0         \n",
      "                                                                 \n",
      " dense_20 (Dense)            (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,658,817\n",
      "Trainable params: 2,658,817\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "21/21 [==============================] - 50s 2s/step - loss: 0.5122 - accuracy: 0.8000 - val_loss: 0.5014 - val_accuracy: 0.8249\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x227e174d5b0>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# RNN Model with Three layer and 0.2 dropout rate\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_features, 128))\n",
    "model.add(SimpleRNN(128, return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(SimpleRNN(128, return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(SimpleRNN(128))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "model.build(X_train)\n",
    "print(model.summary())\n",
    "\n",
    "model.fit(X_train, y_train, batch_size=batch_size, epochs=1,\n",
    "          validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        38\n",
      "           1       0.82      1.00      0.90       179\n",
      "\n",
      "    accuracy                           0.82       217\n",
      "   macro avg       0.41      0.50      0.45       217\n",
      "weighted avg       0.68      0.82      0.75       217\n",
      "\n"
     ]
    }
   ],
   "source": [
    "preds = model.predict(X_test, verbose=0)\n",
    "predictions = [1 if x > 0.5 else 0 for x in preds]\n",
    "print(classification_report(y_test, predictions, zero_division=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_21\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_21 (Embedding)    (None, None, 128)         2560000   \n",
      "                                                                 \n",
      " simple_rnn_15 (SimpleRNN)   (None, None, 128)         32896     \n",
      "                                                                 \n",
      " dropout_39 (Dropout)        (None, None, 128)         0         \n",
      "                                                                 \n",
      " simple_rnn_16 (SimpleRNN)   (None, None, 128)         32896     \n",
      "                                                                 \n",
      " dropout_40 (Dropout)        (None, None, 128)         0         \n",
      "                                                                 \n",
      " simple_rnn_17 (SimpleRNN)   (None, 128)               32896     \n",
      "                                                                 \n",
      " dropout_41 (Dropout)        (None, 128)               0         \n",
      "                                                                 \n",
      " dense_21 (Dense)            (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,658,817\n",
      "Trainable params: 2,658,817\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "21/21 [==============================] - 50s 2s/step - loss: 0.5798 - accuracy: 0.7662 - val_loss: 0.4754 - val_accuracy: 0.8249\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x227bbaef280>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# RNN Model with Three layer and 0.4 dropout rate\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_features, 128))\n",
    "model.add(SimpleRNN(128, return_sequences=True))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(SimpleRNN(128, return_sequences=True))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(SimpleRNN(128))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "model.build(X_train)\n",
    "print(model.summary())\n",
    "\n",
    "model.fit(X_train, y_train, batch_size=batch_size, epochs=1,\n",
    "          validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        38\n",
      "           1       0.82      1.00      0.90       179\n",
      "\n",
      "    accuracy                           0.82       217\n",
      "   macro avg       0.41      0.50      0.45       217\n",
      "weighted avg       0.68      0.82      0.75       217\n",
      "\n"
     ]
    }
   ],
   "source": [
    "preds = model.predict(X_test, verbose=0)\n",
    "predictions = [1 if x > 0.5 else 0 for x in preds]\n",
    "print(classification_report(y_test, predictions, zero_division=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_22\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_22 (Embedding)    (None, None, 128)         2560000   \n",
      "                                                                 \n",
      " simple_rnn_18 (SimpleRNN)   (None, None, 128)         32896     \n",
      "                                                                 \n",
      " dropout_42 (Dropout)        (None, None, 128)         0         \n",
      "                                                                 \n",
      " simple_rnn_19 (SimpleRNN)   (None, None, 128)         32896     \n",
      "                                                                 \n",
      " dropout_43 (Dropout)        (None, None, 128)         0         \n",
      "                                                                 \n",
      " simple_rnn_20 (SimpleRNN)   (None, 128)               32896     \n",
      "                                                                 \n",
      " dropout_44 (Dropout)        (None, 128)               0         \n",
      "                                                                 \n",
      " dense_22 (Dense)            (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,658,817\n",
      "Trainable params: 2,658,817\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "21/21 [==============================] - 50s 2s/step - loss: 0.6565 - accuracy: 0.7354 - val_loss: 0.5033 - val_accuracy: 0.8249\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x227c952cb80>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# RNN Model with Three layer and 0.6 dropout rate\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_features, 128))\n",
    "model.add(SimpleRNN(128, return_sequences=True))\n",
    "model.add(Dropout(0.6))\n",
    "model.add(SimpleRNN(128, return_sequences=True))\n",
    "model.add(Dropout(0.6))\n",
    "model.add(SimpleRNN(128))\n",
    "model.add(Dropout(0.6))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "model.build(X_train)\n",
    "print(model.summary())\n",
    "\n",
    "model.fit(X_train, y_train, batch_size=batch_size, epochs=1,\n",
    "          validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        38\n",
      "           1       0.82      1.00      0.90       179\n",
      "\n",
      "    accuracy                           0.82       217\n",
      "   macro avg       0.41      0.50      0.45       217\n",
      "weighted avg       0.68      0.82      0.75       217\n",
      "\n"
     ]
    }
   ],
   "source": [
    "preds = model.predict(X_test, verbose=0)\n",
    "predictions = [1 if x > 0.5 else 0 for x in preds]\n",
    "print(classification_report(y_test, predictions, zero_division=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_23\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_23 (Embedding)    (None, None, 128)         2560000   \n",
      "                                                                 \n",
      " simple_rnn_21 (SimpleRNN)   (None, None, 128)         32896     \n",
      "                                                                 \n",
      " dropout_45 (Dropout)        (None, None, 128)         0         \n",
      "                                                                 \n",
      " simple_rnn_22 (SimpleRNN)   (None, None, 128)         32896     \n",
      "                                                                 \n",
      " dropout_46 (Dropout)        (None, None, 128)         0         \n",
      "                                                                 \n",
      " simple_rnn_23 (SimpleRNN)   (None, 128)               32896     \n",
      "                                                                 \n",
      " dropout_47 (Dropout)        (None, 128)               0         \n",
      "                                                                 \n",
      " dense_23 (Dense)            (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,658,817\n",
      "Trainable params: 2,658,817\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "21/21 [==============================] - 50s 2s/step - loss: 1.0060 - accuracy: 0.5523 - val_loss: 0.8540 - val_accuracy: 0.8249\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x227bbd30bb0>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# RNN Model with Three layer and 0.8 dropout rate\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_features, 128))\n",
    "model.add(SimpleRNN(128, return_sequences=True))\n",
    "model.add(Dropout(0.8))\n",
    "model.add(SimpleRNN(128, return_sequences=True))\n",
    "model.add(Dropout(0.8))\n",
    "model.add(SimpleRNN(128))\n",
    "model.add(Dropout(0.8))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "model.build(X_train)\n",
    "print(model.summary())\n",
    "\n",
    "model.fit(X_train, y_train, batch_size=batch_size, epochs=1,\n",
    "          validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        38\n",
      "           1       0.82      1.00      0.90       179\n",
      "\n",
      "    accuracy                           0.82       217\n",
      "   macro avg       0.41      0.50      0.45       217\n",
      "weighted avg       0.68      0.82      0.75       217\n",
      "\n"
     ]
    }
   ],
   "source": [
    "preds = model.predict(X_test, verbose=0)\n",
    "predictions = [1 if x > 0.5 else 0 for x in preds]\n",
    "print(classification_report(y_test, predictions, zero_division=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GRU Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_24\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_24 (Embedding)    (None, None, 128)         2560000   \n",
      "                                                                 \n",
      " gru (GRU)                   (None, 128)               98688     \n",
      "                                                                 \n",
      " dropout_48 (Dropout)        (None, 128)               0         \n",
      "                                                                 \n",
      " dense_24 (Dense)            (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,658,817\n",
      "Trainable params: 2,658,817\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "21/21 [==============================] - 120s 6s/step - loss: 0.6090 - accuracy: 0.8062 - val_loss: 0.4704 - val_accuracy: 0.8249\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x227ce62abe0>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# GRU Model with Single layer and 0.2 dropout rate\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_features, 128))\n",
    "model.add(GRU(128))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "model.build(X_train)\n",
    "print(model.summary())\n",
    "\n",
    "model.fit(X_train, y_train, batch_size=batch_size, epochs=1,\n",
    "          validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        38\n",
      "           1       0.82      1.00      0.90       179\n",
      "\n",
      "    accuracy                           0.82       217\n",
      "   macro avg       0.41      0.50      0.45       217\n",
      "weighted avg       0.68      0.82      0.75       217\n",
      "\n"
     ]
    }
   ],
   "source": [
    "preds = model.predict(X_test, verbose=0)\n",
    "predictions = [1 if x > 0.5 else 0 for x in preds]\n",
    "print(classification_report(y_test, predictions, zero_division=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_25\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_25 (Embedding)    (None, None, 128)         2560000   \n",
      "                                                                 \n",
      " gru_1 (GRU)                 (None, 128)               98688     \n",
      "                                                                 \n",
      " dropout_49 (Dropout)        (None, 128)               0         \n",
      "                                                                 \n",
      " dense_25 (Dense)            (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,658,817\n",
      "Trainable params: 2,658,817\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "21/21 [==============================] - 118s 6s/step - loss: 0.5997 - accuracy: 0.8015 - val_loss: 0.4686 - val_accuracy: 0.8249\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x227bbd2cdf0>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# GRU Model with Single layer and 0.4 dropout rate\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_features, 128))\n",
    "model.add(GRU(128))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "model.build(X_train)\n",
    "print(model.summary())\n",
    "\n",
    "model.fit(X_train, y_train, batch_size=batch_size, epochs=1,\n",
    "          validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        38\n",
      "           1       0.82      1.00      0.90       179\n",
      "\n",
      "    accuracy                           0.82       217\n",
      "   macro avg       0.41      0.50      0.45       217\n",
      "weighted avg       0.68      0.82      0.75       217\n",
      "\n"
     ]
    }
   ],
   "source": [
    "preds = model.predict(X_test, verbose=0)\n",
    "predictions = [1 if x > 0.5 else 0 for x in preds]\n",
    "print(classification_report(y_test, predictions, zero_division=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_26\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_26 (Embedding)    (None, None, 128)         2560000   \n",
      "                                                                 \n",
      " gru_2 (GRU)                 (None, 128)               98688     \n",
      "                                                                 \n",
      " dropout_50 (Dropout)        (None, 128)               0         \n",
      "                                                                 \n",
      " dense_26 (Dense)            (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,658,817\n",
      "Trainable params: 2,658,817\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "21/21 [==============================] - 119s 6s/step - loss: 0.6163 - accuracy: 0.7892 - val_loss: 0.4798 - val_accuracy: 0.8249\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x227bbc8e460>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# GRU Model with Single layer and 0.6 dropout rate\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_features, 128))\n",
    "model.add(GRU(128))\n",
    "model.add(Dropout(0.6))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "model.build(X_train)\n",
    "print(model.summary())\n",
    "\n",
    "model.fit(X_train, y_train, batch_size=batch_size, epochs=1,\n",
    "          validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        38\n",
      "           1       0.82      1.00      0.90       179\n",
      "\n",
      "    accuracy                           0.82       217\n",
      "   macro avg       0.41      0.50      0.45       217\n",
      "weighted avg       0.68      0.82      0.75       217\n",
      "\n"
     ]
    }
   ],
   "source": [
    "preds = model.predict(X_test, verbose=0)\n",
    "predictions = [1 if x > 0.5 else 0 for x in preds]\n",
    "print(classification_report(y_test, predictions, zero_division=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_27\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_27 (Embedding)    (None, None, 128)         2560000   \n",
      "                                                                 \n",
      " gru_3 (GRU)                 (None, 128)               98688     \n",
      "                                                                 \n",
      " dropout_51 (Dropout)        (None, 128)               0         \n",
      "                                                                 \n",
      " dense_27 (Dense)            (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,658,817\n",
      "Trainable params: 2,658,817\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "21/21 [==============================] - 119s 6s/step - loss: 0.6185 - accuracy: 0.7754 - val_loss: 0.4837 - val_accuracy: 0.8249\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x227bbb81940>"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# GRU Model with Single layer and 0.8 dropout rate\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_features, 128))\n",
    "model.add(GRU(128))\n",
    "model.add(Dropout(0.8))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "model.build(X_train)\n",
    "print(model.summary())\n",
    "\n",
    "model.fit(X_train, y_train, batch_size=batch_size, epochs=1,\n",
    "          validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        38\n",
      "           1       0.82      1.00      0.90       179\n",
      "\n",
      "    accuracy                           0.82       217\n",
      "   macro avg       0.41      0.50      0.45       217\n",
      "weighted avg       0.68      0.82      0.75       217\n",
      "\n"
     ]
    }
   ],
   "source": [
    "preds = model.predict(X_test, verbose=0)\n",
    "predictions = [1 if x > 0.5 else 0 for x in preds]\n",
    "print(classification_report(y_test, predictions, zero_division=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_28\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_28 (Embedding)    (None, None, 128)         2560000   \n",
      "                                                                 \n",
      " gru_4 (GRU)                 (None, None, 128)         98688     \n",
      "                                                                 \n",
      " dropout_52 (Dropout)        (None, None, 128)         0         \n",
      "                                                                 \n",
      " gru_5 (GRU)                 (None, 128)               98688     \n",
      "                                                                 \n",
      " dropout_53 (Dropout)        (None, 128)               0         \n",
      "                                                                 \n",
      " dense_28 (Dense)            (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,757,505\n",
      "Trainable params: 2,757,505\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "21/21 [==============================] - 241s 12s/step - loss: 0.5548 - accuracy: 0.8046 - val_loss: 0.4810 - val_accuracy: 0.8249\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x227bbb6c280>"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# GRU Model with Two layer and 0.2 dropout rate\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_features, 128))\n",
    "model.add(GRU(128, return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(GRU(128))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "model.build(X_train)\n",
    "print(model.summary())\n",
    "\n",
    "model.fit(X_train, y_train, batch_size=batch_size, epochs=1,\n",
    "          validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        38\n",
      "           1       0.82      1.00      0.90       179\n",
      "\n",
      "    accuracy                           0.82       217\n",
      "   macro avg       0.41      0.50      0.45       217\n",
      "weighted avg       0.68      0.82      0.75       217\n",
      "\n"
     ]
    }
   ],
   "source": [
    "preds = model.predict(X_test, verbose=0)\n",
    "predictions = [1 if x > 0.5 else 0 for x in preds]\n",
    "print(classification_report(y_test, predictions, zero_division=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_29\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_29 (Embedding)    (None, None, 128)         2560000   \n",
      "                                                                 \n",
      " gru_6 (GRU)                 (None, None, 128)         98688     \n",
      "                                                                 \n",
      " dropout_54 (Dropout)        (None, None, 128)         0         \n",
      "                                                                 \n",
      " gru_7 (GRU)                 (None, 128)               98688     \n",
      "                                                                 \n",
      " dropout_55 (Dropout)        (None, 128)               0         \n",
      "                                                                 \n",
      " dense_29 (Dense)            (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,757,505\n",
      "Trainable params: 2,757,505\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "21/21 [==============================] - 341s 16s/step - loss: 0.5375 - accuracy: 0.8077 - val_loss: 0.4676 - val_accuracy: 0.8249\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x227ddaab640>"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# GRU Model with Two layer and 0.4 dropout rate\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_features, 128))\n",
    "model.add(GRU(128, return_sequences=True))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(GRU(128))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "model.build(X_train)\n",
    "print(model.summary())\n",
    "\n",
    "model.fit(X_train, y_train, batch_size=batch_size, epochs=1,\n",
    "          validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        38\n",
      "           1       0.82      1.00      0.90       179\n",
      "\n",
      "    accuracy                           0.82       217\n",
      "   macro avg       0.41      0.50      0.45       217\n",
      "weighted avg       0.68      0.82      0.75       217\n",
      "\n"
     ]
    }
   ],
   "source": [
    "preds = model.predict(X_test, verbose=0)\n",
    "predictions = [1 if x > 0.5 else 0 for x in preds]\n",
    "print(classification_report(y_test, predictions, zero_division=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_30\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_30 (Embedding)    (None, None, 128)         2560000   \n",
      "                                                                 \n",
      " gru_8 (GRU)                 (None, None, 128)         98688     \n",
      "                                                                 \n",
      " dropout_56 (Dropout)        (None, None, 128)         0         \n",
      "                                                                 \n",
      " gru_9 (GRU)                 (None, 128)               98688     \n",
      "                                                                 \n",
      " dropout_57 (Dropout)        (None, 128)               0         \n",
      "                                                                 \n",
      " dense_30 (Dense)            (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,757,505\n",
      "Trainable params: 2,757,505\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "21/21 [==============================] - 261s 13s/step - loss: 0.5698 - accuracy: 0.7969 - val_loss: 0.4680 - val_accuracy: 0.8249\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x227ce5cdca0>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# GRU Model with Two layer and 0.6 dropout rate\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_features, 128))\n",
    "model.add(GRU(128, return_sequences=True))\n",
    "model.add(Dropout(0.6))\n",
    "model.add(GRU(128))\n",
    "model.add(Dropout(0.6))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "model.build(X_train)\n",
    "print(model.summary())\n",
    "\n",
    "model.fit(X_train, y_train, batch_size=batch_size, epochs=1,\n",
    "          validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        38\n",
      "           1       0.82      1.00      0.90       179\n",
      "\n",
      "    accuracy                           0.82       217\n",
      "   macro avg       0.41      0.50      0.45       217\n",
      "weighted avg       0.68      0.82      0.75       217\n",
      "\n"
     ]
    }
   ],
   "source": [
    "preds = model.predict(X_test, verbose=0)\n",
    "predictions = [1 if x > 0.5 else 0 for x in preds]\n",
    "print(classification_report(y_test, predictions, zero_division=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_31\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_31 (Embedding)    (None, None, 128)         2560000   \n",
      "                                                                 \n",
      " gru_10 (GRU)                (None, None, 128)         98688     \n",
      "                                                                 \n",
      " dropout_58 (Dropout)        (None, None, 128)         0         \n",
      "                                                                 \n",
      " gru_11 (GRU)                (None, 128)               98688     \n",
      "                                                                 \n",
      " dropout_59 (Dropout)        (None, 128)               0         \n",
      "                                                                 \n",
      " dense_31 (Dense)            (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,757,505\n",
      "Trainable params: 2,757,505\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "21/21 [==============================] - 233s 11s/step - loss: 0.6062 - accuracy: 0.7938 - val_loss: 0.4652 - val_accuracy: 0.8249\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x227bbbb1b80>"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# GRU Model with Two layer and 0.8 dropout rate\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_features, 128))\n",
    "model.add(GRU(128, return_sequences=True))\n",
    "model.add(Dropout(0.8))\n",
    "model.add(GRU(128))\n",
    "model.add(Dropout(0.8))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "model.build(X_train)\n",
    "print(model.summary())\n",
    "\n",
    "model.fit(X_train, y_train, batch_size=batch_size, epochs=1,\n",
    "          validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        38\n",
      "           1       0.82      1.00      0.90       179\n",
      "\n",
      "    accuracy                           0.82       217\n",
      "   macro avg       0.41      0.50      0.45       217\n",
      "weighted avg       0.68      0.82      0.75       217\n",
      "\n"
     ]
    }
   ],
   "source": [
    "preds = model.predict(X_test, verbose=0)\n",
    "predictions = [1 if x > 0.5 else 0 for x in preds]\n",
    "print(classification_report(y_test, predictions, zero_division=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_32\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_32 (Embedding)    (None, None, 128)         2560000   \n",
      "                                                                 \n",
      " gru_12 (GRU)                (None, None, 128)         98688     \n",
      "                                                                 \n",
      " dropout_60 (Dropout)        (None, None, 128)         0         \n",
      "                                                                 \n",
      " gru_13 (GRU)                (None, None, 128)         98688     \n",
      "                                                                 \n",
      " dropout_61 (Dropout)        (None, None, 128)         0         \n",
      "                                                                 \n",
      " gru_14 (GRU)                (None, 128)               98688     \n",
      "                                                                 \n",
      " dropout_62 (Dropout)        (None, 128)               0         \n",
      "                                                                 \n",
      " dense_32 (Dense)            (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,856,193\n",
      "Trainable params: 2,856,193\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "21/21 [==============================] - 355s 17s/step - loss: 0.5276 - accuracy: 0.8138 - val_loss: 0.4784 - val_accuracy: 0.8249\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x227eaa8f970>"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# GRU Model with Three layer and 0.2 dropout rate\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_features, 128))\n",
    "model.add(GRU(128, return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(GRU(128, return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(GRU(128))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "model.build(X_train)\n",
    "print(model.summary())\n",
    "\n",
    "model.fit(X_train, y_train, batch_size=batch_size, epochs=1,\n",
    "          validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        38\n",
      "           1       0.82      1.00      0.90       179\n",
      "\n",
      "    accuracy                           0.82       217\n",
      "   macro avg       0.41      0.50      0.45       217\n",
      "weighted avg       0.68      0.82      0.75       217\n",
      "\n"
     ]
    }
   ],
   "source": [
    "preds = model.predict(X_test, verbose=0)\n",
    "predictions = [1 if x > 0.5 else 0 for x in preds]\n",
    "print(classification_report(y_test, predictions, zero_division=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_33\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_33 (Embedding)    (None, None, 128)         2560000   \n",
      "                                                                 \n",
      " gru_15 (GRU)                (None, None, 128)         98688     \n",
      "                                                                 \n",
      " dropout_63 (Dropout)        (None, None, 128)         0         \n",
      "                                                                 \n",
      " gru_16 (GRU)                (None, None, 128)         98688     \n",
      "                                                                 \n",
      " dropout_64 (Dropout)        (None, None, 128)         0         \n",
      "                                                                 \n",
      " gru_17 (GRU)                (None, 128)               98688     \n",
      "                                                                 \n",
      " dropout_65 (Dropout)        (None, 128)               0         \n",
      "                                                                 \n",
      " dense_33 (Dense)            (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,856,193\n",
      "Trainable params: 2,856,193\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "21/21 [==============================] - 356s 17s/step - loss: 0.5389 - accuracy: 0.7985 - val_loss: 0.4855 - val_accuracy: 0.8249\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x227bc82bdc0>"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# GRU Model with Three layer and 0.4 dropout rate\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_features, 128))\n",
    "model.add(GRU(128, return_sequences=True))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(GRU(128, return_sequences=True))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(GRU(128))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "model.build(X_train)\n",
    "print(model.summary())\n",
    "\n",
    "model.fit(X_train, y_train, batch_size=batch_size, epochs=1,\n",
    "          validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        38\n",
      "           1       0.82      1.00      0.90       179\n",
      "\n",
      "    accuracy                           0.82       217\n",
      "   macro avg       0.41      0.50      0.45       217\n",
      "weighted avg       0.68      0.82      0.75       217\n",
      "\n"
     ]
    }
   ],
   "source": [
    "preds = model.predict(X_test, verbose=0)\n",
    "predictions = [1 if x > 0.5 else 0 for x in preds]\n",
    "print(classification_report(y_test, predictions, zero_division=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_34\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_34 (Embedding)    (None, None, 128)         2560000   \n",
      "                                                                 \n",
      " gru_18 (GRU)                (None, None, 128)         98688     \n",
      "                                                                 \n",
      " dropout_66 (Dropout)        (None, None, 128)         0         \n",
      "                                                                 \n",
      " gru_19 (GRU)                (None, None, 128)         98688     \n",
      "                                                                 \n",
      " dropout_67 (Dropout)        (None, None, 128)         0         \n",
      "                                                                 \n",
      " gru_20 (GRU)                (None, 128)               98688     \n",
      "                                                                 \n",
      " dropout_68 (Dropout)        (None, 128)               0         \n",
      "                                                                 \n",
      " dense_34 (Dense)            (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,856,193\n",
      "Trainable params: 2,856,193\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "21/21 [==============================] - 358s 17s/step - loss: 0.5462 - accuracy: 0.7923 - val_loss: 0.4658 - val_accuracy: 0.8249\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x227bbc346a0>"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# GRU Model with Three layer and 0.6 dropout rate\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_features, 128))\n",
    "model.add(GRU(128, return_sequences=True))\n",
    "model.add(Dropout(0.6))\n",
    "model.add(GRU(128, return_sequences=True))\n",
    "model.add(Dropout(0.6))\n",
    "model.add(GRU(128))\n",
    "model.add(Dropout(0.6))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "model.build(X_train)\n",
    "print(model.summary())\n",
    "\n",
    "model.fit(X_train, y_train, batch_size=batch_size, epochs=1,\n",
    "          validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        38\n",
      "           1       0.82      1.00      0.90       179\n",
      "\n",
      "    accuracy                           0.82       217\n",
      "   macro avg       0.41      0.50      0.45       217\n",
      "weighted avg       0.68      0.82      0.75       217\n",
      "\n"
     ]
    }
   ],
   "source": [
    "preds = model.predict(X_test, verbose=0)\n",
    "predictions = [1 if x > 0.5 else 0 for x in preds]\n",
    "print(classification_report(y_test, predictions, zero_division=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_35\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_35 (Embedding)    (None, None, 128)         2560000   \n",
      "                                                                 \n",
      " gru_21 (GRU)                (None, None, 128)         98688     \n",
      "                                                                 \n",
      " dropout_69 (Dropout)        (None, None, 128)         0         \n",
      "                                                                 \n",
      " gru_22 (GRU)                (None, None, 128)         98688     \n",
      "                                                                 \n",
      " dropout_70 (Dropout)        (None, None, 128)         0         \n",
      "                                                                 \n",
      " gru_23 (GRU)                (None, 128)               98688     \n",
      "                                                                 \n",
      " dropout_71 (Dropout)        (None, 128)               0         \n",
      "                                                                 \n",
      " dense_35 (Dense)            (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,856,193\n",
      "Trainable params: 2,856,193\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "21/21 [==============================] - 431s 21s/step - loss: 0.5591 - accuracy: 0.7985 - val_loss: 0.4666 - val_accuracy: 0.8249\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x227eaa0ba30>"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# GRU Model with Three layer and 0.8 dropout rate\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_features, 128))\n",
    "model.add(GRU(128, return_sequences=True))\n",
    "model.add(Dropout(0.8))\n",
    "model.add(GRU(128, return_sequences=True))\n",
    "model.add(Dropout(0.8))\n",
    "model.add(GRU(128))\n",
    "model.add(Dropout(0.8))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "model.build(X_train)\n",
    "print(model.summary())\n",
    "\n",
    "model.fit(X_train, y_train, batch_size=batch_size, epochs=1,\n",
    "          validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        38\n",
      "           1       0.82      1.00      0.90       179\n",
      "\n",
      "    accuracy                           0.82       217\n",
      "   macro avg       0.41      0.50      0.45       217\n",
      "weighted avg       0.68      0.82      0.75       217\n",
      "\n"
     ]
    }
   ],
   "source": [
    "preds = model.predict(X_test, verbose=0)\n",
    "predictions = [1 if x > 0.5 else 0 for x in preds]\n",
    "print(classification_report(y_test, predictions, zero_division=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing Data for multi class classification\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>sarcastic</th>\n",
       "      <th>sarcasm</th>\n",
       "      <th>irony</th>\n",
       "      <th>satire</th>\n",
       "      <th>understatement</th>\n",
       "      <th>overstatement</th>\n",
       "      <th>rhetorical_question</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I love it when professors draw a big question ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Today my pop-pop told me I was not “forced” to...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@VolphanCarol @littlewhitty @mysticalmanatee I...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>someone hit me w a horse tranquilizer istg ive...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Loving season 4 of trump does America. Funnies...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               tweet  sarcastic  sarcasm  \\\n",
       "1  I love it when professors draw a big question ...          1      1.0   \n",
       "3  Today my pop-pop told me I was not “forced” to...          1      1.0   \n",
       "4  @VolphanCarol @littlewhitty @mysticalmanatee I...          1      1.0   \n",
       "7  someone hit me w a horse tranquilizer istg ive...          1      1.0   \n",
       "8  Loving season 4 of trump does America. Funnies...          1      1.0   \n",
       "\n",
       "   irony  satire  understatement  overstatement  rhetorical_question  \n",
       "1    0.0     0.0             0.0            0.0                  0.0  \n",
       "3    0.0     0.0             0.0            0.0                  0.0  \n",
       "4    0.0     0.0             0.0            0.0                  0.0  \n",
       "7    0.0     0.0             0.0            0.0                  0.0  \n",
       "8    0.0     0.0             0.0            0.0                  0.0  "
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_multi = tweets.copy()\n",
    "tweets_multi = tweets_multi[tweets.sarcastic == 1]\n",
    "tweets_multi.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_col_to_label(row):\n",
    "    if row.irony == 1.0:\n",
    "        return 'irony'\n",
    "    if row.satire == 1.0:\n",
    "        return 'satire';\n",
    "    if row.understatement == 1.0:\n",
    "        return 'understatement'\n",
    "    if row.overstatement == 1.0:\n",
    "        return 'overstatement'\n",
    "    if row.rhetorical_question == 1.0:\n",
    "        return 'rhetorical_question'\n",
    "    return 'Other'\n",
    "\n",
    "tweets_multi['label'] = tweets_multi.apply(lambda row: convert_col_to_label(row), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_multi = tweets_multi.drop(['sarcasm', 'sarcastic', 'irony', 'satire', 'understatement', 'overstatement', 'rhetorical_question'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "labelencoder = LabelEncoder()\n",
    "tweets_multi['label'] = labelencoder.fit_transform(tweets_multi['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tweets_multi['tweet']\n",
    "y = tweets_multi['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split Train & Test Data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=101, train_size=0.75)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning Multi Class Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_features = 20000\n",
    "EMBEDDING_DIM = 100\n",
    "VALIDATION_SPLIT = 0.25\n",
    "maxlen = 500\n",
    "batch_size = 32\n",
    "classes_len = len(np.unique(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vectorize the text samples into a 2D integer tensor\n",
    "tokenizer = Tokenizer(num_words=max_features)\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "sequences_train = tokenizer.texts_to_sequences(X_train)\n",
    "sequences_test = tokenizer.texts_to_sequences(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pad sequences (samples x time)\n",
      "X_train shape: (534, 500)\n",
      "X_test shape: (179, 500)\n"
     ]
    }
   ],
   "source": [
    "print('Pad sequences (samples x time)')\n",
    "X_train = sequence.pad_sequences(sequences_train, maxlen=maxlen)\n",
    "X_test = sequence.pad_sequences(sequences_test, maxlen=maxlen)\n",
    "\n",
    "\n",
    "print('X_train shape:', X_train.shape)\n",
    "print('X_test shape:', X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_36\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_36 (Embedding)    (None, None, 128)         2560000   \n",
      "                                                                 \n",
      " simple_rnn_24 (SimpleRNN)   (None, 128)               32896     \n",
      "                                                                 \n",
      " dropout_72 (Dropout)        (None, 128)               0         \n",
      "                                                                 \n",
      " dense_36 (Dense)            (None, 6)                 774       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,593,670\n",
      "Trainable params: 2,593,670\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "17/17 [==============================] - 17s 996ms/step - loss: 0.9700 - accuracy: 0.7434 - val_loss: 0.7325 - val_accuracy: 0.7877\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x227edcd2940>"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# RNN Model with Single layer and 0.2 dropout rate\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_features, 128))\n",
    "model.add(SimpleRNN(128))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(classes_len, activation='softmax'))\n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "model.build(X_train)\n",
    "print(model.summary())\n",
    "\n",
    "model.fit(X_train, y_train, batch_size=batch_size, epochs=1,\n",
    "          validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      1.00      0.88       141\n",
      "           3       0.00      0.00      0.00        28\n",
      "           1       0.00      0.00      0.00         0\n",
      "           5       0.00      0.00      0.00         3\n",
      "           4       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00         5\n",
      "\n",
      "   micro avg       0.79      0.79      0.79       179\n",
      "   macro avg       0.13      0.17      0.15       179\n",
      "weighted avg       0.62      0.79      0.69       179\n",
      "\n"
     ]
    }
   ],
   "source": [
    "preds = model.predict(X_test, verbose=0)\n",
    "predictions = [np.argmax(x) for x in preds]\n",
    "print(classification_report(y_test, predictions, zero_division=0, labels=tweets_multi.label.unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_37\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_37 (Embedding)    (None, None, 128)         2560000   \n",
      "                                                                 \n",
      " simple_rnn_25 (SimpleRNN)   (None, 128)               32896     \n",
      "                                                                 \n",
      " dropout_73 (Dropout)        (None, 128)               0         \n",
      "                                                                 \n",
      " dense_37 (Dense)            (None, 6)                 774       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,593,670\n",
      "Trainable params: 2,593,670\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "17/17 [==============================] - 16s 948ms/step - loss: 0.9634 - accuracy: 0.7603 - val_loss: 0.7372 - val_accuracy: 0.7877\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x227ea76dac0>"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# RNN Model with Single layer and 0.4 dropout rate\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_features, 128))\n",
    "model.add(SimpleRNN(128))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(classes_len, activation='softmax'))\n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "model.build(X_train)\n",
    "print(model.summary())\n",
    "\n",
    "model.fit(X_train, y_train, batch_size=batch_size, epochs=1,\n",
    "          validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      1.00      0.88       141\n",
      "           3       0.00      0.00      0.00        28\n",
      "           1       0.00      0.00      0.00         0\n",
      "           5       0.00      0.00      0.00         3\n",
      "           4       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00         5\n",
      "\n",
      "   micro avg       0.79      0.79      0.79       179\n",
      "   macro avg       0.13      0.17      0.15       179\n",
      "weighted avg       0.62      0.79      0.69       179\n",
      "\n"
     ]
    }
   ],
   "source": [
    "preds = model.predict(X_test, verbose=0)\n",
    "predictions = [np.argmax(x) for x in preds]\n",
    "print(classification_report(y_test, predictions, zero_division=0, labels=tweets_multi.label.unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_38\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_38 (Embedding)    (None, None, 128)         2560000   \n",
      "                                                                 \n",
      " simple_rnn_26 (SimpleRNN)   (None, 128)               32896     \n",
      "                                                                 \n",
      " dropout_74 (Dropout)        (None, 128)               0         \n",
      "                                                                 \n",
      " dense_38 (Dense)            (None, 6)                 774       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,593,670\n",
      "Trainable params: 2,593,670\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "17/17 [==============================] - 17s 992ms/step - loss: 1.0336 - accuracy: 0.7079 - val_loss: 0.9229 - val_accuracy: 0.7877\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x227ee0a6670>"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# RNN Model with Single layer and 0.6 dropout rate\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_features, 128))\n",
    "model.add(SimpleRNN(128))\n",
    "model.add(Dropout(0.6))\n",
    "model.add(Dense(classes_len, activation='softmax'))\n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "model.build(X_train)\n",
    "print(model.summary())\n",
    "\n",
    "model.fit(X_train, y_train, batch_size=batch_size, epochs=1,\n",
    "          validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      1.00      0.88       141\n",
      "           3       0.00      0.00      0.00        28\n",
      "           1       0.00      0.00      0.00         0\n",
      "           5       0.00      0.00      0.00         3\n",
      "           4       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00         5\n",
      "\n",
      "   micro avg       0.79      0.79      0.79       179\n",
      "   macro avg       0.13      0.17      0.15       179\n",
      "weighted avg       0.62      0.79      0.69       179\n",
      "\n"
     ]
    }
   ],
   "source": [
    "preds = model.predict(X_test, verbose=0)\n",
    "predictions = [np.argmax(x) for x in preds]\n",
    "print(classification_report(y_test, predictions, zero_division=0, labels=tweets_multi.label.unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_39\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_39 (Embedding)    (None, None, 128)         2560000   \n",
      "                                                                 \n",
      " simple_rnn_27 (SimpleRNN)   (None, 128)               32896     \n",
      "                                                                 \n",
      " dropout_75 (Dropout)        (None, 128)               0         \n",
      "                                                                 \n",
      " dense_39 (Dense)            (None, 6)                 774       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,593,670\n",
      "Trainable params: 2,593,670\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "17/17 [==============================] - 16s 940ms/step - loss: 1.1451 - accuracy: 0.6011 - val_loss: 0.7519 - val_accuracy: 0.7877\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x227e1800130>"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# RNN Model with Single layer and 0.8 dropout rate\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_features, 128))\n",
    "model.add(SimpleRNN(128))\n",
    "model.add(Dropout(0.8))\n",
    "model.add(Dense(classes_len, activation='softmax'))\n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "model.build(X_train)\n",
    "print(model.summary())\n",
    "\n",
    "model.fit(X_train, y_train, batch_size=batch_size, epochs=1,\n",
    "          validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      1.00      0.88       141\n",
      "           3       0.00      0.00      0.00        28\n",
      "           1       0.00      0.00      0.00         0\n",
      "           5       0.00      0.00      0.00         3\n",
      "           4       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00         5\n",
      "\n",
      "   micro avg       0.79      0.79      0.79       179\n",
      "   macro avg       0.13      0.17      0.15       179\n",
      "weighted avg       0.62      0.79      0.69       179\n",
      "\n"
     ]
    }
   ],
   "source": [
    "preds = model.predict(X_test, verbose=0)\n",
    "predictions = [np.argmax(x) for x in preds]\n",
    "print(classification_report(y_test, predictions, zero_division=0, labels=tweets_multi.label.unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_40\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_40 (Embedding)    (None, None, 128)         2560000   \n",
      "                                                                 \n",
      " simple_rnn_28 (SimpleRNN)   (None, None, 128)         32896     \n",
      "                                                                 \n",
      " dropout_76 (Dropout)        (None, None, 128)         0         \n",
      "                                                                 \n",
      " simple_rnn_29 (SimpleRNN)   (None, 128)               32896     \n",
      "                                                                 \n",
      " dropout_77 (Dropout)        (None, 128)               0         \n",
      "                                                                 \n",
      " dense_40 (Dense)            (None, 6)                 774       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,626,566\n",
      "Trainable params: 2,626,566\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "17/17 [==============================] - 35s 2s/step - loss: 1.0074 - accuracy: 0.6985 - val_loss: 0.8390 - val_accuracy: 0.7877\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x227ea8f31f0>"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# RNN Model with Two layer and 0.2 dropout rate\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_features, 128))\n",
    "model.add(SimpleRNN(128, return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(SimpleRNN(128))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(classes_len, activation='softmax'))\n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "model.build(X_train)\n",
    "print(model.summary())\n",
    "\n",
    "model.fit(X_train, y_train, batch_size=batch_size, epochs=1,\n",
    "          validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      1.00      0.88       141\n",
      "           3       0.00      0.00      0.00        28\n",
      "           1       0.00      0.00      0.00         0\n",
      "           5       0.00      0.00      0.00         3\n",
      "           4       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00         5\n",
      "\n",
      "   micro avg       0.79      0.79      0.79       179\n",
      "   macro avg       0.13      0.17      0.15       179\n",
      "weighted avg       0.62      0.79      0.69       179\n",
      "\n"
     ]
    }
   ],
   "source": [
    "preds = model.predict(X_test, verbose=0)\n",
    "predictions = [np.argmax(x) for x in preds]\n",
    "print(classification_report(y_test, predictions, zero_division=0, labels=tweets_multi.label.unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_41\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_41 (Embedding)    (None, None, 128)         2560000   \n",
      "                                                                 \n",
      " simple_rnn_30 (SimpleRNN)   (None, None, 128)         32896     \n",
      "                                                                 \n",
      " dropout_78 (Dropout)        (None, None, 128)         0         \n",
      "                                                                 \n",
      " simple_rnn_31 (SimpleRNN)   (None, 128)               32896     \n",
      "                                                                 \n",
      " dropout_79 (Dropout)        (None, 128)               0         \n",
      "                                                                 \n",
      " dense_41 (Dense)            (None, 6)                 774       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,626,566\n",
      "Trainable params: 2,626,566\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "17/17 [==============================] - 39s 2s/step - loss: 1.0397 - accuracy: 0.7022 - val_loss: 0.7373 - val_accuracy: 0.7877\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x227bbb591c0>"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# RNN Model with Two layer and 0.4 dropout rate\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_features, 128))\n",
    "model.add(SimpleRNN(128, return_sequences=True))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(SimpleRNN(128))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(classes_len, activation='softmax'))\n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "model.build(X_train)\n",
    "print(model.summary())\n",
    "\n",
    "model.fit(X_train, y_train, batch_size=batch_size, epochs=1,\n",
    "          validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      1.00      0.88       141\n",
      "           3       0.00      0.00      0.00        28\n",
      "           1       0.00      0.00      0.00         0\n",
      "           5       0.00      0.00      0.00         3\n",
      "           4       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00         5\n",
      "\n",
      "   micro avg       0.79      0.79      0.79       179\n",
      "   macro avg       0.13      0.17      0.15       179\n",
      "weighted avg       0.62      0.79      0.69       179\n",
      "\n"
     ]
    }
   ],
   "source": [
    "preds = model.predict(X_test, verbose=0)\n",
    "predictions = [np.argmax(x) for x in preds]\n",
    "print(classification_report(y_test, predictions, zero_division=0, labels=tweets_multi.label.unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_42\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_42 (Embedding)    (None, None, 128)         2560000   \n",
      "                                                                 \n",
      " simple_rnn_32 (SimpleRNN)   (None, None, 128)         32896     \n",
      "                                                                 \n",
      " dropout_80 (Dropout)        (None, None, 128)         0         \n",
      "                                                                 \n",
      " simple_rnn_33 (SimpleRNN)   (None, 128)               32896     \n",
      "                                                                 \n",
      " dropout_81 (Dropout)        (None, 128)               0         \n",
      "                                                                 \n",
      " dense_42 (Dense)            (None, 6)                 774       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,626,566\n",
      "Trainable params: 2,626,566\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "17/17 [==============================] - 41s 2s/step - loss: 1.1460 - accuracy: 0.6629 - val_loss: 0.7708 - val_accuracy: 0.7877\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x227e7bba700>"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# RNN Model with Two layer and 0.6 dropout rate\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_features, 128))\n",
    "model.add(SimpleRNN(128, return_sequences=True))\n",
    "model.add(Dropout(0.6))\n",
    "model.add(SimpleRNN(128))\n",
    "model.add(Dropout(0.6))\n",
    "model.add(Dense(classes_len, activation='softmax'))\n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "model.build(X_train)\n",
    "print(model.summary())\n",
    "\n",
    "model.fit(X_train, y_train, batch_size=batch_size, epochs=1,\n",
    "          validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      1.00      0.88       141\n",
      "           3       0.00      0.00      0.00        28\n",
      "           1       0.00      0.00      0.00         0\n",
      "           5       0.00      0.00      0.00         3\n",
      "           4       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00         5\n",
      "\n",
      "   micro avg       0.79      0.79      0.79       179\n",
      "   macro avg       0.13      0.17      0.15       179\n",
      "weighted avg       0.62      0.79      0.69       179\n",
      "\n"
     ]
    }
   ],
   "source": [
    "preds = model.predict(X_test, verbose=0)\n",
    "predictions = [np.argmax(x) for x in preds]\n",
    "print(classification_report(y_test, predictions, zero_division=0, labels=tweets_multi.label.unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_43\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_43 (Embedding)    (None, None, 128)         2560000   \n",
      "                                                                 \n",
      " simple_rnn_34 (SimpleRNN)   (None, None, 128)         32896     \n",
      "                                                                 \n",
      " dropout_82 (Dropout)        (None, None, 128)         0         \n",
      "                                                                 \n",
      " simple_rnn_35 (SimpleRNN)   (None, 128)               32896     \n",
      "                                                                 \n",
      " dropout_83 (Dropout)        (None, 128)               0         \n",
      "                                                                 \n",
      " dense_43 (Dense)            (None, 6)                 774       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,626,566\n",
      "Trainable params: 2,626,566\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "17/17 [==============================] - 31s 2s/step - loss: 1.5900 - accuracy: 0.4925 - val_loss: 1.1903 - val_accuracy: 0.7877\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x227e14f3b20>"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# RNN Model with Two layer and 0.8 dropout rate\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_features, 128))\n",
    "model.add(SimpleRNN(128, return_sequences=True))\n",
    "model.add(Dropout(0.8))\n",
    "model.add(SimpleRNN(128))\n",
    "model.add(Dropout(0.8))\n",
    "model.add(Dense(classes_len, activation='softmax'))\n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "model.build(X_train)\n",
    "print(model.summary())\n",
    "\n",
    "model.fit(X_train, y_train, batch_size=batch_size, epochs=1,\n",
    "          validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      1.00      0.88       141\n",
      "           3       0.00      0.00      0.00        28\n",
      "           1       0.00      0.00      0.00         0\n",
      "           5       0.00      0.00      0.00         3\n",
      "           4       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00         5\n",
      "\n",
      "   micro avg       0.79      0.79      0.79       179\n",
      "   macro avg       0.13      0.17      0.15       179\n",
      "weighted avg       0.62      0.79      0.69       179\n",
      "\n"
     ]
    }
   ],
   "source": [
    "preds = model.predict(X_test, verbose=0)\n",
    "predictions = [np.argmax(x) for x in preds]\n",
    "print(classification_report(y_test, predictions, zero_division=0, labels=tweets_multi.label.unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_44\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_44 (Embedding)    (None, None, 128)         2560000   \n",
      "                                                                 \n",
      " simple_rnn_36 (SimpleRNN)   (None, None, 128)         32896     \n",
      "                                                                 \n",
      " dropout_84 (Dropout)        (None, None, 128)         0         \n",
      "                                                                 \n",
      " simple_rnn_37 (SimpleRNN)   (None, None, 128)         32896     \n",
      "                                                                 \n",
      " dropout_85 (Dropout)        (None, None, 128)         0         \n",
      "                                                                 \n",
      " simple_rnn_38 (SimpleRNN)   (None, 128)               32896     \n",
      "                                                                 \n",
      " dropout_86 (Dropout)        (None, 128)               0         \n",
      "                                                                 \n",
      " dense_44 (Dense)            (None, 6)                 774       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,659,462\n",
      "Trainable params: 2,659,462\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "17/17 [==============================] - 55s 3s/step - loss: 0.9232 - accuracy: 0.7491 - val_loss: 0.7377 - val_accuracy: 0.7877\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x227e18d4e20>"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# RNN Model with Three layer and 0.2 dropout rate\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_features, 128))\n",
    "model.add(SimpleRNN(128, return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(SimpleRNN(128, return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(SimpleRNN(128))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(classes_len, activation='softmax'))\n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "model.build(X_train)\n",
    "print(model.summary())\n",
    "\n",
    "model.fit(X_train, y_train, batch_size=batch_size, epochs=1,\n",
    "          validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      1.00      0.88       141\n",
      "           3       0.00      0.00      0.00        28\n",
      "           1       0.00      0.00      0.00         0\n",
      "           5       0.00      0.00      0.00         3\n",
      "           4       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00         5\n",
      "\n",
      "   micro avg       0.79      0.79      0.79       179\n",
      "   macro avg       0.13      0.17      0.15       179\n",
      "weighted avg       0.62      0.79      0.69       179\n",
      "\n"
     ]
    }
   ],
   "source": [
    "preds = model.predict(X_test, verbose=0)\n",
    "predictions = [np.argmax(x) for x in preds]\n",
    "print(classification_report(y_test, predictions, zero_division=0, labels=tweets_multi.label.unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_45\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_45 (Embedding)    (None, None, 128)         2560000   \n",
      "                                                                 \n",
      " simple_rnn_39 (SimpleRNN)   (None, None, 128)         32896     \n",
      "                                                                 \n",
      " dropout_87 (Dropout)        (None, None, 128)         0         \n",
      "                                                                 \n",
      " simple_rnn_40 (SimpleRNN)   (None, None, 128)         32896     \n",
      "                                                                 \n",
      " dropout_88 (Dropout)        (None, None, 128)         0         \n",
      "                                                                 \n",
      " simple_rnn_41 (SimpleRNN)   (None, 128)               32896     \n",
      "                                                                 \n",
      " dropout_89 (Dropout)        (None, 128)               0         \n",
      "                                                                 \n",
      " dense_45 (Dense)            (None, 6)                 774       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,659,462\n",
      "Trainable params: 2,659,462\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "17/17 [==============================] - 57s 3s/step - loss: 1.2109 - accuracy: 0.6592 - val_loss: 0.7054 - val_accuracy: 0.7877\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x227bbc2bd60>"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# RNN Model with Three layer and 0.4 dropout rate\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_features, 128))\n",
    "model.add(SimpleRNN(128, return_sequences=True))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(SimpleRNN(128, return_sequences=True))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(SimpleRNN(128))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(classes_len, activation='softmax'))\n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "model.build(X_train)\n",
    "print(model.summary())\n",
    "\n",
    "model.fit(X_train, y_train, batch_size=batch_size, epochs=1,\n",
    "          validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      1.00      0.88       141\n",
      "           3       0.00      0.00      0.00        28\n",
      "           1       0.00      0.00      0.00         0\n",
      "           5       0.00      0.00      0.00         3\n",
      "           4       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00         5\n",
      "\n",
      "   micro avg       0.79      0.79      0.79       179\n",
      "   macro avg       0.13      0.17      0.15       179\n",
      "weighted avg       0.62      0.79      0.69       179\n",
      "\n"
     ]
    }
   ],
   "source": [
    "preds = model.predict(X_test, verbose=0)\n",
    "predictions = [np.argmax(x) for x in preds]\n",
    "print(classification_report(y_test, predictions, zero_division=0, labels=tweets_multi.label.unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_46\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_46 (Embedding)    (None, None, 128)         2560000   \n",
      "                                                                 \n",
      " simple_rnn_42 (SimpleRNN)   (None, None, 128)         32896     \n",
      "                                                                 \n",
      " dropout_90 (Dropout)        (None, None, 128)         0         \n",
      "                                                                 \n",
      " simple_rnn_43 (SimpleRNN)   (None, None, 128)         32896     \n",
      "                                                                 \n",
      " dropout_91 (Dropout)        (None, None, 128)         0         \n",
      "                                                                 \n",
      " simple_rnn_44 (SimpleRNN)   (None, 128)               32896     \n",
      "                                                                 \n",
      " dropout_92 (Dropout)        (None, 128)               0         \n",
      "                                                                 \n",
      " dense_46 (Dense)            (None, 6)                 774       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,659,462\n",
      "Trainable params: 2,659,462\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "17/17 [==============================] - 57s 3s/step - loss: 1.4142 - accuracy: 0.6273 - val_loss: 1.1098 - val_accuracy: 0.7877\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x227f32df190>"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# RNN Model with Three layer and 0.6 dropout rate\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_features, 128))\n",
    "model.add(SimpleRNN(128, return_sequences=True))\n",
    "model.add(Dropout(0.6))\n",
    "model.add(SimpleRNN(128, return_sequences=True))\n",
    "model.add(Dropout(0.6))\n",
    "model.add(SimpleRNN(128))\n",
    "model.add(Dropout(0.6))\n",
    "model.add(Dense(classes_len, activation='softmax'))\n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "model.build(X_train)\n",
    "print(model.summary())\n",
    "\n",
    "model.fit(X_train, y_train, batch_size=batch_size, epochs=1,\n",
    "          validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      1.00      0.88       141\n",
      "           3       0.00      0.00      0.00        28\n",
      "           1       0.00      0.00      0.00         0\n",
      "           5       0.00      0.00      0.00         3\n",
      "           4       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00         5\n",
      "\n",
      "   micro avg       0.79      0.79      0.79       179\n",
      "   macro avg       0.13      0.17      0.15       179\n",
      "weighted avg       0.62      0.79      0.69       179\n",
      "\n"
     ]
    }
   ],
   "source": [
    "preds = model.predict(X_test, verbose=0)\n",
    "predictions = [np.argmax(x) for x in preds]\n",
    "print(classification_report(y_test, predictions, zero_division=0, labels=tweets_multi.label.unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_47\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_47 (Embedding)    (None, None, 128)         2560000   \n",
      "                                                                 \n",
      " simple_rnn_45 (SimpleRNN)   (None, None, 128)         32896     \n",
      "                                                                 \n",
      " dropout_93 (Dropout)        (None, None, 128)         0         \n",
      "                                                                 \n",
      " simple_rnn_46 (SimpleRNN)   (None, None, 128)         32896     \n",
      "                                                                 \n",
      " dropout_94 (Dropout)        (None, None, 128)         0         \n",
      "                                                                 \n",
      " simple_rnn_47 (SimpleRNN)   (None, 128)               32896     \n",
      "                                                                 \n",
      " dropout_95 (Dropout)        (None, 128)               0         \n",
      "                                                                 \n",
      " dense_47 (Dense)            (None, 6)                 774       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,659,462\n",
      "Trainable params: 2,659,462\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "17/17 [==============================] - 55s 3s/step - loss: 3.0717 - accuracy: 0.1816 - val_loss: 1.0248 - val_accuracy: 0.7430\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x227ea773f70>"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# RNN Model with Three layer and 0.8 dropout rate\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_features, 128))\n",
    "model.add(SimpleRNN(128, return_sequences=True))\n",
    "model.add(Dropout(0.8))\n",
    "model.add(SimpleRNN(128, return_sequences=True))\n",
    "model.add(Dropout(0.8))\n",
    "model.add(SimpleRNN(128))\n",
    "model.add(Dropout(0.8))\n",
    "model.add(Dense(classes_len, activation='softmax'))\n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "model.build(X_train)\n",
    "print(model.summary())\n",
    "\n",
    "model.fit(X_train, y_train, batch_size=batch_size, epochs=1,\n",
    "          validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.94      0.85       141\n",
      "           3       0.10      0.04      0.05        28\n",
      "           1       0.00      0.00      0.00         0\n",
      "           5       0.00      0.00      0.00         3\n",
      "           4       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00         5\n",
      "\n",
      "   micro avg       0.74      0.74      0.74       179\n",
      "   macro avg       0.15      0.16      0.15       179\n",
      "weighted avg       0.63      0.74      0.68       179\n",
      "\n"
     ]
    }
   ],
   "source": [
    "preds = model.predict(X_test, verbose=0)\n",
    "predictions = [np.argmax(x) for x in preds]\n",
    "print(classification_report(y_test, predictions, zero_division=0, labels=tweets_multi.label.unique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_48\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_48 (Embedding)    (None, None, 128)         2560000   \n",
      "                                                                 \n",
      " lstm_24 (LSTM)              (None, 128)               131584    \n",
      "                                                                 \n",
      " dropout_96 (Dropout)        (None, 128)               0         \n",
      "                                                                 \n",
      " dense_48 (Dense)            (None, 6)                 774       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,692,358\n",
      "Trainable params: 2,692,358\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "17/17 [==============================] - 104s 6s/step - loss: 1.2898 - accuracy: 0.7360 - val_loss: 0.7888 - val_accuracy: 0.7877\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x227e7920af0>"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# LSTM Model with Single layer and 0.2 dropout rate\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_features, 128))\n",
    "model.add(LSTM(128))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(classes_len, activation='softmax'))\n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "model.build(X_train)\n",
    "print(model.summary())\n",
    "\n",
    "model.fit(X_train, y_train, batch_size=batch_size, epochs=1,\n",
    "          validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      1.00      0.88       141\n",
      "           3       0.00      0.00      0.00        28\n",
      "           1       0.00      0.00      0.00         0\n",
      "           5       0.00      0.00      0.00         3\n",
      "           4       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00         5\n",
      "\n",
      "   micro avg       0.79      0.79      0.79       179\n",
      "   macro avg       0.13      0.17      0.15       179\n",
      "weighted avg       0.62      0.79      0.69       179\n",
      "\n"
     ]
    }
   ],
   "source": [
    "preds = model.predict(X_test, verbose=0)\n",
    "predictions = [np.argmax(x) for x in preds]\n",
    "print(classification_report(y_test, predictions, zero_division=0, labels=tweets_multi.label.unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_49\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_49 (Embedding)    (None, None, 128)         2560000   \n",
      "                                                                 \n",
      " lstm_25 (LSTM)              (None, 128)               131584    \n",
      "                                                                 \n",
      " dropout_97 (Dropout)        (None, 128)               0         \n",
      "                                                                 \n",
      " dense_49 (Dense)            (None, 6)                 774       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,692,358\n",
      "Trainable params: 2,692,358\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "17/17 [==============================] - 100s 6s/step - loss: 1.2985 - accuracy: 0.7491 - val_loss: 0.8567 - val_accuracy: 0.7877\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x227bbc89460>"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# LSTM Model with Single layer and 0.4 dropout rate\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_features, 128))\n",
    "model.add(LSTM(128))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(classes_len, activation='softmax'))\n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "model.build(X_train)\n",
    "print(model.summary())\n",
    "\n",
    "model.fit(X_train, y_train, batch_size=batch_size, epochs=1,\n",
    "          validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      1.00      0.88       141\n",
      "           3       0.00      0.00      0.00        28\n",
      "           1       0.00      0.00      0.00         0\n",
      "           5       0.00      0.00      0.00         3\n",
      "           4       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00         5\n",
      "\n",
      "   micro avg       0.79      0.79      0.79       179\n",
      "   macro avg       0.13      0.17      0.15       179\n",
      "weighted avg       0.62      0.79      0.69       179\n",
      "\n"
     ]
    }
   ],
   "source": [
    "preds = model.predict(X_test, verbose=0)\n",
    "predictions = [np.argmax(x) for x in preds]\n",
    "print(classification_report(y_test, predictions, zero_division=0, labels=tweets_multi.label.unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_50\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_50 (Embedding)    (None, None, 128)         2560000   \n",
      "                                                                 \n",
      " lstm_26 (LSTM)              (None, 128)               131584    \n",
      "                                                                 \n",
      " dropout_98 (Dropout)        (None, 128)               0         \n",
      "                                                                 \n",
      " dense_50 (Dense)            (None, 6)                 774       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,692,358\n",
      "Trainable params: 2,692,358\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "17/17 [==============================] - 123s 7s/step - loss: 1.3916 - accuracy: 0.7434 - val_loss: 0.7491 - val_accuracy: 0.7877\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x227e78f4670>"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# LSTM Model with Single layer and 0.6 dropout rate\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_features, 128))\n",
    "model.add(LSTM(128))\n",
    "model.add(Dropout(0.6))\n",
    "model.add(Dense(classes_len, activation='softmax'))\n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "model.build(X_train)\n",
    "print(model.summary())\n",
    "\n",
    "model.fit(X_train, y_train, batch_size=batch_size, epochs=1,\n",
    "          validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      1.00      0.88       141\n",
      "           3       0.00      0.00      0.00        28\n",
      "           1       0.00      0.00      0.00         0\n",
      "           5       0.00      0.00      0.00         3\n",
      "           4       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00         5\n",
      "\n",
      "   micro avg       0.79      0.79      0.79       179\n",
      "   macro avg       0.13      0.17      0.15       179\n",
      "weighted avg       0.62      0.79      0.69       179\n",
      "\n"
     ]
    }
   ],
   "source": [
    "preds = model.predict(X_test, verbose=0)\n",
    "predictions = [np.argmax(x) for x in preds]\n",
    "print(classification_report(y_test, predictions, zero_division=0, labels=tweets_multi.label.unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_51\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_51 (Embedding)    (None, None, 128)         2560000   \n",
      "                                                                 \n",
      " lstm_27 (LSTM)              (None, 128)               131584    \n",
      "                                                                 \n",
      " dropout_99 (Dropout)        (None, 128)               0         \n",
      "                                                                 \n",
      " dense_51 (Dense)            (None, 6)                 774       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,692,358\n",
      "Trainable params: 2,692,358\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "17/17 [==============================] - 109s 6s/step - loss: 1.4065 - accuracy: 0.6854 - val_loss: 0.9057 - val_accuracy: 0.7877\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x227bc3530a0>"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# LSTM Model with Single layer and 0.8 dropout rate\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_features, 128))\n",
    "model.add(LSTM(128))\n",
    "model.add(Dropout(0.8))\n",
    "model.add(Dense(classes_len, activation='softmax'))\n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "model.build(X_train)\n",
    "print(model.summary())\n",
    "\n",
    "model.fit(X_train, y_train, batch_size=batch_size, epochs=1,\n",
    "          validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      1.00      0.88       141\n",
      "           3       0.00      0.00      0.00        28\n",
      "           1       0.00      0.00      0.00         0\n",
      "           5       0.00      0.00      0.00         3\n",
      "           4       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00         5\n",
      "\n",
      "   micro avg       0.79      0.79      0.79       179\n",
      "   macro avg       0.13      0.17      0.15       179\n",
      "weighted avg       0.62      0.79      0.69       179\n",
      "\n"
     ]
    }
   ],
   "source": [
    "preds = model.predict(X_test, verbose=0)\n",
    "predictions = [np.argmax(x) for x in preds]\n",
    "print(classification_report(y_test, predictions, zero_division=0, labels=tweets_multi.label.unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_52\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_52 (Embedding)    (None, None, 128)         2560000   \n",
      "                                                                 \n",
      " lstm_28 (LSTM)              (None, None, 128)         131584    \n",
      "                                                                 \n",
      " dropout_100 (Dropout)       (None, None, 128)         0         \n",
      "                                                                 \n",
      " lstm_29 (LSTM)              (None, 128)               131584    \n",
      "                                                                 \n",
      " dropout_101 (Dropout)       (None, 128)               0         \n",
      "                                                                 \n",
      " dense_52 (Dense)            (None, 6)                 774       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,823,942\n",
      "Trainable params: 2,823,942\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "17/17 [==============================] - 256s 15s/step - loss: 1.2780 - accuracy: 0.7491 - val_loss: 0.7672 - val_accuracy: 0.7877\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x227bbda61c0>"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# LSTM Model with Two layer and 0.8 dropout rate\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_features, 128))\n",
    "model.add(LSTM(128, return_sequences=True))\n",
    "model.add(Dropout(0.8))\n",
    "model.add(LSTM(128))\n",
    "model.add(Dropout(0.8))\n",
    "model.add(Dense(classes_len, activation='softmax'))\n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "model.build(X_train)\n",
    "print(model.summary())\n",
    "\n",
    "model.fit(X_train, y_train, batch_size=batch_size, epochs=1,\n",
    "          validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      1.00      0.88       141\n",
      "           3       0.00      0.00      0.00        28\n",
      "           1       0.00      0.00      0.00         0\n",
      "           5       0.00      0.00      0.00         3\n",
      "           4       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00         5\n",
      "\n",
      "   micro avg       0.79      0.79      0.79       179\n",
      "   macro avg       0.13      0.17      0.15       179\n",
      "weighted avg       0.62      0.79      0.69       179\n",
      "\n"
     ]
    }
   ],
   "source": [
    "preds = model.predict(X_test, verbose=0)\n",
    "predictions = [np.argmax(x) for x in preds]\n",
    "print(classification_report(y_test, predictions, zero_division=0, labels=tweets_multi.label.unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_53\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_53 (Embedding)    (None, None, 128)         2560000   \n",
      "                                                                 \n",
      " lstm_30 (LSTM)              (None, None, 128)         131584    \n",
      "                                                                 \n",
      " dropout_102 (Dropout)       (None, None, 128)         0         \n",
      "                                                                 \n",
      " lstm_31 (LSTM)              (None, 128)               131584    \n",
      "                                                                 \n",
      " dropout_103 (Dropout)       (None, 128)               0         \n",
      "                                                                 \n",
      " dense_53 (Dense)            (None, 6)                 774       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,823,942\n",
      "Trainable params: 2,823,942\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "17/17 [==============================] - 260s 15s/step - loss: 1.1682 - accuracy: 0.7678 - val_loss: 0.7158 - val_accuracy: 0.7877\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x227e7781220>"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# LSTM Model with Two layer and 0.6 dropout rate\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_features, 128))\n",
    "model.add(LSTM(128, return_sequences=True))\n",
    "model.add(Dropout(0.6))\n",
    "model.add(LSTM(128))\n",
    "model.add(Dropout(0.6))\n",
    "model.add(Dense(classes_len, activation='softmax'))\n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "model.build(X_train)\n",
    "print(model.summary())\n",
    "\n",
    "model.fit(X_train, y_train, batch_size=batch_size, epochs=1,\n",
    "          validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      1.00      0.88       141\n",
      "           3       0.00      0.00      0.00        28\n",
      "           1       0.00      0.00      0.00         0\n",
      "           5       0.00      0.00      0.00         3\n",
      "           4       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00         5\n",
      "\n",
      "   micro avg       0.79      0.79      0.79       179\n",
      "   macro avg       0.13      0.17      0.15       179\n",
      "weighted avg       0.62      0.79      0.69       179\n",
      "\n"
     ]
    }
   ],
   "source": [
    "preds = model.predict(X_test, verbose=0)\n",
    "predictions = [np.argmax(x) for x in preds]\n",
    "print(classification_report(y_test, predictions, zero_division=0, labels=tweets_multi.label.unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_54\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_54 (Embedding)    (None, None, 128)         2560000   \n",
      "                                                                 \n",
      " lstm_32 (LSTM)              (None, None, 128)         131584    \n",
      "                                                                 \n",
      " dropout_104 (Dropout)       (None, None, 128)         0         \n",
      "                                                                 \n",
      " lstm_33 (LSTM)              (None, 128)               131584    \n",
      "                                                                 \n",
      " dropout_105 (Dropout)       (None, 128)               0         \n",
      "                                                                 \n",
      " dense_54 (Dense)            (None, 6)                 774       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,823,942\n",
      "Trainable params: 2,823,942\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "17/17 [==============================] - 244s 14s/step - loss: 1.1702 - accuracy: 0.7547 - val_loss: 0.7242 - val_accuracy: 0.7877\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x227ea7b18e0>"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# LSTM Model with Two layer and 0.4 dropout rate\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_features, 128))\n",
    "model.add(LSTM(128, return_sequences=True))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(LSTM(128))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(classes_len, activation='softmax'))\n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "model.build(X_train)\n",
    "print(model.summary())\n",
    "\n",
    "model.fit(X_train, y_train, batch_size=batch_size, epochs=1,\n",
    "          validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      1.00      0.88       141\n",
      "           3       0.00      0.00      0.00        28\n",
      "           1       0.00      0.00      0.00         0\n",
      "           5       0.00      0.00      0.00         3\n",
      "           4       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00         5\n",
      "\n",
      "   micro avg       0.79      0.79      0.79       179\n",
      "   macro avg       0.13      0.17      0.15       179\n",
      "weighted avg       0.62      0.79      0.69       179\n",
      "\n"
     ]
    }
   ],
   "source": [
    "preds = model.predict(X_test, verbose=0)\n",
    "predictions = [np.argmax(x) for x in preds]\n",
    "print(classification_report(y_test, predictions, zero_division=0, labels=tweets_multi.label.unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_55\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_55 (Embedding)    (None, None, 128)         2560000   \n",
      "                                                                 \n",
      " lstm_34 (LSTM)              (None, None, 128)         131584    \n",
      "                                                                 \n",
      " dropout_106 (Dropout)       (None, None, 128)         0         \n",
      "                                                                 \n",
      " lstm_35 (LSTM)              (None, 128)               131584    \n",
      "                                                                 \n",
      " dropout_107 (Dropout)       (None, 128)               0         \n",
      "                                                                 \n",
      " dense_55 (Dense)            (None, 6)                 774       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,823,942\n",
      "Trainable params: 2,823,942\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "17/17 [==============================] - 276s 16s/step - loss: 1.2210 - accuracy: 0.7659 - val_loss: 0.7398 - val_accuracy: 0.7877\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x227eaa49280>"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# LSTM Model with Two layer and 0.2 dropout rate\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_features, 128))\n",
    "model.add(LSTM(128, return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(128))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(classes_len, activation='softmax'))\n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "model.build(X_train)\n",
    "print(model.summary())\n",
    "\n",
    "model.fit(X_train, y_train, batch_size=batch_size, epochs=1,\n",
    "          validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      1.00      0.88       141\n",
      "           3       0.00      0.00      0.00        28\n",
      "           1       0.00      0.00      0.00         0\n",
      "           5       0.00      0.00      0.00         3\n",
      "           4       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00         5\n",
      "\n",
      "   micro avg       0.79      0.79      0.79       179\n",
      "   macro avg       0.13      0.17      0.15       179\n",
      "weighted avg       0.62      0.79      0.69       179\n",
      "\n"
     ]
    }
   ],
   "source": [
    "preds = model.predict(X_test, verbose=0)\n",
    "predictions = [np.argmax(x) for x in preds]\n",
    "print(classification_report(y_test, predictions, zero_division=0, labels=tweets_multi.label.unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_56\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_56 (Embedding)    (None, None, 128)         2560000   \n",
      "                                                                 \n",
      " lstm_36 (LSTM)              (None, None, 128)         131584    \n",
      "                                                                 \n",
      " dropout_108 (Dropout)       (None, None, 128)         0         \n",
      "                                                                 \n",
      " lstm_37 (LSTM)              (None, None, 128)         131584    \n",
      "                                                                 \n",
      " dropout_109 (Dropout)       (None, None, 128)         0         \n",
      "                                                                 \n",
      " lstm_38 (LSTM)              (None, 128)               131584    \n",
      "                                                                 \n",
      " dropout_110 (Dropout)       (None, 128)               0         \n",
      "                                                                 \n",
      " dense_56 (Dense)            (None, 6)                 774       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,955,526\n",
      "Trainable params: 2,955,526\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "17/17 [==============================] - 422s 25s/step - loss: 1.0931 - accuracy: 0.7697 - val_loss: 0.7322 - val_accuracy: 0.7877\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x227c54181f0>"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# LSTM Model with Three layer and 0.2 dropout rate\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_features, 128))\n",
    "model.add(LSTM(128, return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(128, return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(128))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(classes_len, activation='softmax'))\n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "model.build(X_train)\n",
    "print(model.summary())\n",
    "\n",
    "model.fit(X_train, y_train, batch_size=batch_size, epochs=1,\n",
    "          validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      1.00      0.88       141\n",
      "           3       0.00      0.00      0.00        28\n",
      "           1       0.00      0.00      0.00         0\n",
      "           5       0.00      0.00      0.00         3\n",
      "           4       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00         5\n",
      "\n",
      "   micro avg       0.79      0.79      0.79       179\n",
      "   macro avg       0.13      0.17      0.15       179\n",
      "weighted avg       0.62      0.79      0.69       179\n",
      "\n"
     ]
    }
   ],
   "source": [
    "preds = model.predict(X_test, verbose=0)\n",
    "predictions = [np.argmax(x) for x in preds]\n",
    "print(classification_report(y_test, predictions, zero_division=0, labels=tweets_multi.label.unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_57\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_57 (Embedding)    (None, None, 128)         2560000   \n",
      "                                                                 \n",
      " lstm_39 (LSTM)              (None, None, 128)         131584    \n",
      "                                                                 \n",
      " dropout_111 (Dropout)       (None, None, 128)         0         \n",
      "                                                                 \n",
      " lstm_40 (LSTM)              (None, None, 128)         131584    \n",
      "                                                                 \n",
      " dropout_112 (Dropout)       (None, None, 128)         0         \n",
      "                                                                 \n",
      " lstm_41 (LSTM)              (None, 128)               131584    \n",
      "                                                                 \n",
      " dropout_113 (Dropout)       (None, 128)               0         \n",
      "                                                                 \n",
      " dense_57 (Dense)            (None, 6)                 774       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,955,526\n",
      "Trainable params: 2,955,526\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "17/17 [==============================] - 376s 22s/step - loss: 1.0646 - accuracy: 0.7678 - val_loss: 0.7377 - val_accuracy: 0.7877\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x227bbbe2d30>"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# LSTM Model with Three layer and 0.4 dropout rate\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_features, 128))\n",
    "model.add(LSTM(128, return_sequences=True))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(LSTM(128, return_sequences=True))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(LSTM(128))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(classes_len, activation='softmax'))\n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "model.build(X_train)\n",
    "print(model.summary())\n",
    "\n",
    "model.fit(X_train, y_train, batch_size=batch_size, epochs=1,\n",
    "          validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      1.00      0.88       141\n",
      "           3       0.00      0.00      0.00        28\n",
      "           1       0.00      0.00      0.00         0\n",
      "           5       0.00      0.00      0.00         3\n",
      "           4       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00         5\n",
      "\n",
      "   micro avg       0.79      0.79      0.79       179\n",
      "   macro avg       0.13      0.17      0.15       179\n",
      "weighted avg       0.62      0.79      0.69       179\n",
      "\n"
     ]
    }
   ],
   "source": [
    "preds = model.predict(X_test, verbose=0)\n",
    "predictions = [np.argmax(x) for x in preds]\n",
    "print(classification_report(y_test, predictions, zero_division=0, labels=tweets_multi.label.unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_58\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_58 (Embedding)    (None, None, 128)         2560000   \n",
      "                                                                 \n",
      " lstm_42 (LSTM)              (None, None, 128)         131584    \n",
      "                                                                 \n",
      " dropout_114 (Dropout)       (None, None, 128)         0         \n",
      "                                                                 \n",
      " lstm_43 (LSTM)              (None, None, 128)         131584    \n",
      "                                                                 \n",
      " dropout_115 (Dropout)       (None, None, 128)         0         \n",
      "                                                                 \n",
      " lstm_44 (LSTM)              (None, 128)               131584    \n",
      "                                                                 \n",
      " dropout_116 (Dropout)       (None, 128)               0         \n",
      "                                                                 \n",
      " dense_58 (Dense)            (None, 6)                 774       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,955,526\n",
      "Trainable params: 2,955,526\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "17/17 [==============================] - 469s 28s/step - loss: 1.1646 - accuracy: 0.7640 - val_loss: 0.7530 - val_accuracy: 0.7877\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x227c54187f0>"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# LSTM Model with Three layer and 0.6 dropout rate\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_features, 128))\n",
    "model.add(LSTM(128, return_sequences=True))\n",
    "model.add(Dropout(0.6))\n",
    "model.add(LSTM(128, return_sequences=True))\n",
    "model.add(Dropout(0.6))\n",
    "model.add(LSTM(128))\n",
    "model.add(Dropout(0.6))\n",
    "model.add(Dense(classes_len, activation='softmax'))\n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "model.build(X_train)\n",
    "print(model.summary())\n",
    "\n",
    "model.fit(X_train, y_train, batch_size=batch_size, epochs=1,\n",
    "          validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      1.00      0.88       141\n",
      "           3       0.00      0.00      0.00        28\n",
      "           1       0.00      0.00      0.00         0\n",
      "           5       0.00      0.00      0.00         3\n",
      "           4       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00         5\n",
      "\n",
      "   micro avg       0.79      0.79      0.79       179\n",
      "   macro avg       0.13      0.17      0.15       179\n",
      "weighted avg       0.62      0.79      0.69       179\n",
      "\n"
     ]
    }
   ],
   "source": [
    "preds = model.predict(X_test, verbose=0)\n",
    "predictions = [np.argmax(x) for x in preds]\n",
    "print(classification_report(y_test, predictions, zero_division=0, labels=tweets_multi.label.unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_59\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_59 (Embedding)    (None, None, 128)         2560000   \n",
      "                                                                 \n",
      " lstm_45 (LSTM)              (None, None, 128)         131584    \n",
      "                                                                 \n",
      " dropout_117 (Dropout)       (None, None, 128)         0         \n",
      "                                                                 \n",
      " lstm_46 (LSTM)              (None, None, 128)         131584    \n",
      "                                                                 \n",
      " dropout_118 (Dropout)       (None, None, 128)         0         \n",
      "                                                                 \n",
      " lstm_47 (LSTM)              (None, 128)               131584    \n",
      "                                                                 \n",
      " dropout_119 (Dropout)       (None, 128)               0         \n",
      "                                                                 \n",
      " dense_59 (Dense)            (None, 6)                 774       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,955,526\n",
      "Trainable params: 2,955,526\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "17/17 [==============================] - 458s 27s/step - loss: 1.2095 - accuracy: 0.7509 - val_loss: 0.7778 - val_accuracy: 0.7877\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x227e7401fd0>"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# LSTM Model with Three layer and 0.8 dropout rate\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_features, 128))\n",
    "model.add(LSTM(128, return_sequences=True))\n",
    "model.add(Dropout(0.8))\n",
    "model.add(LSTM(128, return_sequences=True))\n",
    "model.add(Dropout(0.8))\n",
    "model.add(LSTM(128))\n",
    "model.add(Dropout(0.8))\n",
    "model.add(Dense(classes_len, activation='softmax'))\n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "model.build(X_train)\n",
    "print(model.summary())\n",
    "\n",
    "model.fit(X_train, y_train, batch_size=batch_size, epochs=1,\n",
    "          validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      1.00      0.88       141\n",
      "           3       0.00      0.00      0.00        28\n",
      "           1       0.00      0.00      0.00         0\n",
      "           5       0.00      0.00      0.00         3\n",
      "           4       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00         5\n",
      "\n",
      "   micro avg       0.79      0.79      0.79       179\n",
      "   macro avg       0.13      0.17      0.15       179\n",
      "weighted avg       0.62      0.79      0.69       179\n",
      "\n"
     ]
    }
   ],
   "source": [
    "preds = model.predict(X_test, verbose=0)\n",
    "predictions = [np.argmax(x) for x in preds]\n",
    "print(classification_report(y_test, predictions, zero_division=0, labels=tweets_multi.label.unique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GRU Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_60\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_60 (Embedding)    (None, None, 128)         2560000   \n",
      "                                                                 \n",
      " gru_24 (GRU)                (None, 128)               98688     \n",
      "                                                                 \n",
      " dropout_120 (Dropout)       (None, 128)               0         \n",
      "                                                                 \n",
      " dense_60 (Dense)            (None, 6)                 774       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,659,462\n",
      "Trainable params: 2,659,462\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "17/17 [==============================] - 121s 7s/step - loss: 1.4875 - accuracy: 0.7378 - val_loss: 1.1906 - val_accuracy: 0.7877\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x22800229a00>"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# GRU Model with Single layer and 0.2 dropout rate\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_features, 128))\n",
    "model.add(GRU(128))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(classes_len, activation='softmax'))\n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "model.build(X_train)\n",
    "print(model.summary())\n",
    "\n",
    "model.fit(X_train, y_train, batch_size=batch_size, epochs=1,\n",
    "          validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      1.00      0.88       141\n",
      "           3       0.00      0.00      0.00        28\n",
      "           1       0.00      0.00      0.00         0\n",
      "           5       0.00      0.00      0.00         3\n",
      "           4       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00         5\n",
      "\n",
      "   micro avg       0.79      0.79      0.79       179\n",
      "   macro avg       0.13      0.17      0.15       179\n",
      "weighted avg       0.62      0.79      0.69       179\n",
      "\n"
     ]
    }
   ],
   "source": [
    "preds = model.predict(X_test, verbose=0)\n",
    "predictions = [np.argmax(x) for x in preds]\n",
    "print(classification_report(y_test, predictions, zero_division=0, labels=tweets_multi.label.unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_61\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_61 (Embedding)    (None, None, 128)         2560000   \n",
      "                                                                 \n",
      " gru_25 (GRU)                (None, 128)               98688     \n",
      "                                                                 \n",
      " dropout_121 (Dropout)       (None, 128)               0         \n",
      "                                                                 \n",
      " dense_61 (Dense)            (None, 6)                 774       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,659,462\n",
      "Trainable params: 2,659,462\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "17/17 [==============================] - 120s 7s/step - loss: 1.5636 - accuracy: 0.7154 - val_loss: 0.8432 - val_accuracy: 0.7877\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x227f315e8b0>"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# GRU Model with Single layer and 0.4 dropout rate\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_features, 128))\n",
    "model.add(GRU(128))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(classes_len, activation='softmax'))\n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "model.build(X_train)\n",
    "print(model.summary())\n",
    "\n",
    "model.fit(X_train, y_train, batch_size=batch_size, epochs=1,\n",
    "          validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      1.00      0.88       141\n",
      "           3       0.00      0.00      0.00        28\n",
      "           1       0.00      0.00      0.00         0\n",
      "           5       0.00      0.00      0.00         3\n",
      "           4       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00         5\n",
      "\n",
      "   micro avg       0.79      0.79      0.79       179\n",
      "   macro avg       0.13      0.17      0.15       179\n",
      "weighted avg       0.62      0.79      0.69       179\n",
      "\n"
     ]
    }
   ],
   "source": [
    "preds = model.predict(X_test, verbose=0)\n",
    "predictions = [np.argmax(x) for x in preds]\n",
    "print(classification_report(y_test, predictions, zero_division=0, labels=tweets_multi.label.unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_62\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_62 (Embedding)    (None, None, 128)         2560000   \n",
      "                                                                 \n",
      " gru_26 (GRU)                (None, 128)               98688     \n",
      "                                                                 \n",
      " dropout_122 (Dropout)       (None, 128)               0         \n",
      "                                                                 \n",
      " dense_62 (Dense)            (None, 6)                 774       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,659,462\n",
      "Trainable params: 2,659,462\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      " 5/17 [=======>......................] - ETA: 1:14 - loss: 1.7694 - accuracy: 0.4938"
     ]
    }
   ],
   "source": [
    "# GRU Model with Single layer and 0.6 dropout rate\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_features, 128))\n",
    "model.add(GRU(128))\n",
    "model.add(Dropout(0.6))\n",
    "model.add(Dense(classes_len, activation='softmax'))\n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "model.build(X_train)\n",
    "print(model.summary())\n",
    "\n",
    "model.fit(X_train, y_train, batch_size=batch_size, epochs=1,\n",
    "          validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model.predict(X_test, verbose=0)\n",
    "predictions = [np.argmax(x) for x in preds]\n",
    "print(classification_report(y_test, predictions, zero_division=0, labels=tweets_multi.label.unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GRU Model with Single layer and 0.8 dropout rate\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_features, 128))\n",
    "model.add(GRU(128))\n",
    "model.add(Dropout(0.8))\n",
    "model.add(Dense(classes_len, activation='softmax'))\n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "model.build(X_train)\n",
    "print(model.summary())\n",
    "\n",
    "model.fit(X_train, y_train, batch_size=batch_size, epochs=1,\n",
    "          validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model.predict(X_test, verbose=0)\n",
    "predictions = [np.argmax(x) for x in preds]\n",
    "print(classification_report(y_test, predictions, zero_division=0, labels=tweets_multi.label.unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GRU Model with Two layer and 0.2 dropout rate\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_features, 128))\n",
    "model.add(GRU(128, return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(GRU(128))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(classes_len, activation='softmax'))\n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "model.build(X_train)\n",
    "print(model.summary())\n",
    "\n",
    "model.fit(X_train, y_train, batch_size=batch_size, epochs=1,\n",
    "          validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model.predict(X_test, verbose=0)\n",
    "predictions = [np.argmax(x) for x in preds]\n",
    "print(classification_report(y_test, predictions, zero_division=0, labels=tweets_multi.label.unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GRU Model with Two layer and 0.4 dropout rate\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_features, 128))\n",
    "model.add(GRU(128, return_sequences=True))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(GRU(128))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(classes_len, activation='softmax'))\n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "model.build(X_train)\n",
    "print(model.summary())\n",
    "\n",
    "model.fit(X_train, y_train, batch_size=batch_size, epochs=1,\n",
    "          validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model.predict(X_test, verbose=0)\n",
    "predictions = [np.argmax(x) for x in preds]\n",
    "print(classification_report(y_test, predictions, zero_division=0, labels=tweets_multi.label.unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GRU Model with Two layer and 0.6 dropout rate\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_features, 128))\n",
    "model.add(GRU(128, return_sequences=True))\n",
    "model.add(Dropout(0.6))\n",
    "model.add(GRU(128))\n",
    "model.add(Dropout(0.6))\n",
    "model.add(Dense(classes_len, activation='softmax'))\n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "model.build(X_train)\n",
    "print(model.summary())\n",
    "\n",
    "model.fit(X_train, y_train, batch_size=batch_size, epochs=1,\n",
    "          validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model.predict(X_test, verbose=0)\n",
    "predictions = [np.argmax(x) for x in preds]\n",
    "print(classification_report(y_test, predictions, zero_division=0, labels=tweets_multi.label.unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GRU Model with Two layer and 0.8 dropout rate\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_features, 128))\n",
    "model.add(GRU(128, return_sequences=True))\n",
    "model.add(Dropout(0.8))\n",
    "model.add(GRU(128))\n",
    "model.add(Dropout(0.8))\n",
    "model.add(Dense(classes_len, activation='softmax'))\n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "model.build(X_train)\n",
    "print(model.summary())\n",
    "\n",
    "model.fit(X_train, y_train, batch_size=batch_size, epochs=1,\n",
    "          validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model.predict(X_test, verbose=0)\n",
    "predictions = [np.argmax(x) for x in preds]\n",
    "print(classification_report(y_test, predictions, zero_division=0, labels=tweets_multi.label.unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GRU Model with Three layer and 0.2 dropout rate\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_features, 128))\n",
    "model.add(GRU(128, return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(GRU(128, return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(GRU(128))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(classes_len, activation='softmax'))\n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "model.build(X_train)\n",
    "print(model.summary())\n",
    "\n",
    "model.fit(X_train, y_train, batch_size=batch_size, epochs=1,\n",
    "          validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model.predict(X_test, verbose=0)\n",
    "predictions = [np.argmax(x) for x in preds]\n",
    "print(classification_report(y_test, predictions, zero_division=0, labels=tweets_multi.label.unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GRU Model with Three layer and 0.4 dropout rate\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_features, 128))\n",
    "model.add(GRU(128, return_sequences=True))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(GRU(128, return_sequences=True))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(GRU(128))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(classes_len, activation='softmax'))\n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "model.build(X_train)\n",
    "print(model.summary())\n",
    "\n",
    "model.fit(X_train, y_train, batch_size=batch_size, epochs=1,\n",
    "          validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model.predict(X_test, verbose=0)\n",
    "predictions = [np.argmax(x) for x in preds]\n",
    "print(classification_report(y_test, predictions, zero_division=0, labels=tweets_multi.label.unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GRU Model with Three layer and 0.6 dropout rate\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_features, 128))\n",
    "model.add(GRU(128, return_sequences=True))\n",
    "model.add(Dropout(0.6))\n",
    "model.add(GRU(128, return_sequences=True))\n",
    "model.add(Dropout(0.6))\n",
    "model.add(GRU(128))\n",
    "model.add(Dropout(0.6))\n",
    "model.add(Dense(classes_len, activation='softmax'))\n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "model.build(X_train)\n",
    "print(model.summary())\n",
    "\n",
    "model.fit(X_train, y_train, batch_size=batch_size, epochs=1,\n",
    "          validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model.predict(X_test, verbose=0)\n",
    "predictions = [np.argmax(x) for x in preds]\n",
    "print(classification_report(y_test, predictions, zero_division=0, labels=tweets_multi.label.unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GRU Model with Three layer and 0.8 dropout rate\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_features, 128))\n",
    "model.add(GRU(128, return_sequences=True))\n",
    "model.add(Dropout(0.8))\n",
    "model.add(GRU(128, return_sequences=True))\n",
    "model.add(Dropout(0.8))\n",
    "model.add(GRU(128))\n",
    "model.add(Dropout(0.8))\n",
    "model.add(Dense(classes_len, activation='softmax'))\n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "model.build(X_train)\n",
    "print(model.summary())\n",
    "\n",
    "model.fit(X_train, y_train, batch_size=batch_size, epochs=1,\n",
    "          validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model.predict(X_test, verbose=0)\n",
    "predictions = [np.argmax(x) for x in preds]\n",
    "print(classification_report(y_test, predictions, zero_division=0, labels=tweets_multi.label.unique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BiLSTM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LSTM Model with Single layer and 0.2 dropout rate\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_features, 128))\n",
    "model.add(Bidirectional(LSTM(128)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(classes_len, activation='softmax'))\n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "model.build(X_train)\n",
    "print(model.summary())\n",
    "\n",
    "model.fit(X_train, y_train, batch_size=batch_size, epochs=1,\n",
    "          validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model.predict(X_test, verbose=0)\n",
    "predictions = [np.argmax(x) for x in preds]\n",
    "print(classification_report(y_test, predictions, zero_division=0, labels=tweets_multi.label.unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LSTM Model with Single layer and 0.4 dropout rate\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_features, 128))\n",
    "model.add(Bidirectional(LSTM(128)))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(classes_len, activation='softmax'))\n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "model.build(X_train)\n",
    "print(model.summary())\n",
    "\n",
    "model.fit(X_train, y_train, batch_size=batch_size, epochs=1,\n",
    "          validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model.predict(X_test, verbose=0)\n",
    "predictions = [np.argmax(x) for x in preds]\n",
    "print(classification_report(y_test, predictions, zero_division=0, labels=tweets_multi.label.unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LSTM Model with Single layer and 0.6 dropout rate\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_features, 128))\n",
    "model.add(Bidirectional(LSTM(128)))\n",
    "model.add(Dropout(0.6))\n",
    "model.add(Dense(classes_len, activation='softmax'))\n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "model.build(X_train)\n",
    "print(model.summary())\n",
    "\n",
    "model.fit(X_train, y_train, batch_size=batch_size, epochs=1,\n",
    "          validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model.predict(X_test, verbose=0)\n",
    "predictions = [np.argmax(x) for x in preds]\n",
    "print(classification_report(y_test, predictions, zero_division=0, labels=tweets_multi.label.unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LSTM Model with Single layer and 0.8 dropout rate\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_features, 128))\n",
    "model.add(Bidirectional(LSTM(128)))\n",
    "model.add(Dropout(0.8))\n",
    "model.add(Dense(classes_len, activation='softmax'))\n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "model.build(X_train)\n",
    "print(model.summary())\n",
    "\n",
    "model.fit(X_train, y_train, batch_size=batch_size, epochs=1,\n",
    "          validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model.predict(X_test, verbose=0)\n",
    "predictions = [np.argmax(x) for x in preds]\n",
    "print(classification_report(y_test, predictions, zero_division=0, labels=tweets_multi.label.unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LSTM Model with Two layer and 0.2 dropout rate\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_features, 128))\n",
    "model.add(Bidirectional(LSTM(128, return_sequences=True)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Bidirectional(LSTM(128)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(classes_len, activation='softmax'))\n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "model.build(X_train)\n",
    "print(model.summary())\n",
    "\n",
    "model.fit(X_train, y_train, batch_size=batch_size, epochs=1,\n",
    "          validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model.predict(X_test, verbose=0)\n",
    "predictions = [np.argmax(x) for x in preds]\n",
    "print(classification_report(y_test, predictions, zero_division=0, labels=tweets_multi.label.unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LSTM Model with Two layer and 0.4 dropout rate\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_features, 128))\n",
    "model.add(Bidirectional(LSTM(128, return_sequences=True)))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Bidirectional(LSTM(128)))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(classes_len, activation='softmax'))\n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "model.build(X_train)\n",
    "print(model.summary())\n",
    "\n",
    "model.fit(X_train, y_train, batch_size=batch_size, epochs=1,\n",
    "          validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model.predict(X_test, verbose=0)\n",
    "predictions = [np.argmax(x) for x in preds]\n",
    "print(classification_report(y_test, predictions, zero_division=0, labels=tweets_multi.label.unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LSTM Model with Two layer and 0.6 dropout rate\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_features, 128))\n",
    "model.add(Bidirectional(LSTM(128, return_sequences=True)))\n",
    "model.add(Dropout(0.6))\n",
    "model.add(Bidirectional(LSTM(128)))\n",
    "model.add(Dropout(0.6))\n",
    "model.add(Dense(classes_len, activation='softmax'))\n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "model.build(X_train)\n",
    "print(model.summary())\n",
    "\n",
    "model.fit(X_train, y_train, batch_size=batch_size, epochs=1,\n",
    "          validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model.predict(X_test, verbose=0)\n",
    "predictions = [np.argmax(x) for x in preds]\n",
    "print(classification_report(y_test, predictions, zero_division=0, labels=tweets_multi.label.unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LSTM Model with Two layer and 0.8 dropout rate\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_features, 128))\n",
    "model.add(Bidirectional(LSTM(128, return_sequences=True)))\n",
    "model.add(Dropout(0.8))\n",
    "model.add(Bidirectional(LSTM(128)))\n",
    "model.add(Dropout(0.8))\n",
    "model.add(Dense(classes_len, activation='softmax'))\n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "model.build(X_train)\n",
    "print(model.summary())\n",
    "\n",
    "model.fit(X_train, y_train, batch_size=batch_size, epochs=1,\n",
    "          validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model.predict(X_test, verbose=0)\n",
    "predictions = [np.argmax(x) for x in preds]\n",
    "print(classification_report(y_test, predictions, zero_division=0, labels=tweets_multi.label.unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LSTM Model with Three layer and 0.2 dropout rate\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_features, 128))\n",
    "model.add(Bidirectional(LSTM(128, return_sequences=True)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Bidirectional(LSTM(128, return_sequences=True)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Bidirectional(LSTM(128)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(classes_len, activation='softmax'))\n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "model.build(X_train)\n",
    "print(model.summary())\n",
    "\n",
    "model.fit(X_train, y_train, batch_size=batch_size, epochs=1,\n",
    "          validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model.predict(X_test, verbose=0)\n",
    "predictions = [np.argmax(x) for x in preds]\n",
    "print(classification_report(y_test, predictions, zero_division=0, labels=tweets_multi.label.unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LSTM Model with Three layer and 0.4 dropout rate\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_features, 128))\n",
    "model.add(Bidirectional(LSTM(128, return_sequences=True)))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Bidirectional(LSTM(128, return_sequences=True)))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Bidirectional(LSTM(128)))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(classes_len, activation='softmax'))\n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "model.build(X_train)\n",
    "print(model.summary())\n",
    "\n",
    "model.fit(X_train, y_train, batch_size=batch_size, epochs=1,\n",
    "          validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model.predict(X_test, verbose=0)\n",
    "predictions = [np.argmax(x) for x in preds]\n",
    "print(classification_report(y_test, predictions, zero_division=0, labels=tweets_multi.label.unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LSTM Model with Three layer and 0.6 dropout rate\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_features, 128))\n",
    "model.add(Bidirectional(LSTM(128, return_sequences=True)))\n",
    "model.add(Dropout(0.6))\n",
    "model.add(Bidirectional(LSTM(128, return_sequences=True)))\n",
    "model.add(Dropout(0.6))\n",
    "model.add(Bidirectional(LSTM(128)))\n",
    "model.add(Dropout(0.6))\n",
    "model.add(Dense(classes_len, activation='softmax'))\n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "model.build(X_train)\n",
    "print(model.summary())\n",
    "\n",
    "model.fit(X_train, y_train, batch_size=batch_size, epochs=1,\n",
    "          validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model.predict(X_test, verbose=0)\n",
    "predictions = [np.argmax(x) for x in preds]\n",
    "print(classification_report(y_test, predictions, zero_division=0, labels=tweets_multi.label.unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LSTM Model with Three layer and 0.8 dropout rate\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_features, 128))\n",
    "model.add(Bidirectional(LSTM(128, return_sequences=True)))\n",
    "model.add(Dropout(0.8))\n",
    "model.add(Bidirectional(LSTM(128, return_sequences=True)))\n",
    "model.add(Dropout(0.8))\n",
    "model.add(Bidirectional(LSTM(128)))\n",
    "model.add(Dropout(0.8))\n",
    "model.add(Dense(classes_len, activation='softmax'))\n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "model.build(X_train)\n",
    "print(model.summary())\n",
    "\n",
    "model.fit(X_train, y_train, batch_size=batch_size, epochs=1,\n",
    "          validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model.predict(X_test, verbose=0)\n",
    "predictions = [np.argmax(x) for x in preds]\n",
    "print(classification_report(y_test, predictions, zero_division=0, labels=tweets_multi.label.unique()))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5d681dc4c5cbd80cc618676dd6169611bafe3b7d10cc745436a35486ed14f444"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
