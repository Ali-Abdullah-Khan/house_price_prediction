{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\khawaja maaz\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (1.3.4)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in c:\\users\\khawaja maaz\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2017.3 in c:\\users\\khawaja maaz\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from pandas) (2021.3)\n",
      "Requirement already satisfied: numpy>=1.17.3 in c:\\users\\khawaja maaz\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from pandas) (1.21.4)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\khawaja maaz\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from python-dateutil>=2.7.3->pandas) (1.16.0)\n",
      "Requirement already satisfied: sklearn in c:\\users\\khawaja maaz\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (0.0)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\khawaja maaz\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from sklearn) (1.0.1)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\khawaja maaz\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from scikit-learn->sklearn) (1.1.0)\n",
      "Requirement already satisfied: scipy>=1.1.0 in c:\\users\\khawaja maaz\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from scikit-learn->sklearn) (1.7.3)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\khawaja maaz\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from scikit-learn->sklearn) (3.0.0)\n",
      "Requirement already satisfied: numpy>=1.14.6 in c:\\users\\khawaja maaz\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from scikit-learn->sklearn) (1.21.4)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\khawaja maaz\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (3.5.0)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\khawaja maaz\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from matplotlib) (8.4.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\khawaja maaz\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from matplotlib) (4.28.2)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\khawaja maaz\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\khawaja maaz\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from matplotlib) (1.21.4)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\khawaja maaz\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from matplotlib) (1.3.2)\n",
      "Requirement already satisfied: setuptools-scm>=4 in c:\\users\\khawaja maaz\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from matplotlib) (6.3.2)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\khawaja maaz\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from matplotlib) (21.3)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in c:\\users\\khawaja maaz\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from matplotlib) (3.0.6)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\khawaja maaz\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\khawaja maaz\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "Requirement already satisfied: tomli>=1.0.0 in c:\\users\\khawaja maaz\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from setuptools-scm>=4->matplotlib) (1.2.2)\n",
      "Requirement already satisfied: setuptools in c:\\users\\khawaja maaz\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from setuptools-scm>=4->matplotlib) (56.0.0)\n",
      "Requirement already satisfied: keras in c:\\users\\khawaja maaz\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (2.7.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas\n",
    "!pip install sklearn\n",
    "!pip install matplotlib\n",
    "!pip install keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>tweet</th>\n",
       "      <th>sarcastic</th>\n",
       "      <th>sarcasm</th>\n",
       "      <th>irony</th>\n",
       "      <th>satire</th>\n",
       "      <th>understatement</th>\n",
       "      <th>overstatement</th>\n",
       "      <th>rhetorical_question</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>The only thing I got from college is a caffein...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>I love it when professors draw a big question ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Remember the hundred emails from companies whe...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Today my pop-pop told me I was not “forced” to...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>@VolphanCarol @littlewhitty @mysticalmanatee I...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                              tweet  sarcastic  \\\n",
       "0           0  The only thing I got from college is a caffein...          1   \n",
       "1           1  I love it when professors draw a big question ...          1   \n",
       "2           2  Remember the hundred emails from companies whe...          1   \n",
       "3           3  Today my pop-pop told me I was not “forced” to...          1   \n",
       "4           4  @VolphanCarol @littlewhitty @mysticalmanatee I...          1   \n",
       "\n",
       "   sarcasm  irony  satire  understatement  overstatement  rhetorical_question  \n",
       "0      0.0    1.0     0.0             0.0            0.0                  0.0  \n",
       "1      1.0    0.0     0.0             0.0            0.0                  0.0  \n",
       "2      0.0    1.0     0.0             0.0            0.0                  0.0  \n",
       "3      1.0    0.0     0.0             0.0            0.0                  0.0  \n",
       "4      1.0    0.0     0.0             0.0            0.0                  0.0  "
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets = pd.read_csv(\"sarcasm_dataset.csv\")\n",
    "\n",
    "tweets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>sarcastic</th>\n",
       "      <th>sarcasm</th>\n",
       "      <th>irony</th>\n",
       "      <th>satire</th>\n",
       "      <th>understatement</th>\n",
       "      <th>overstatement</th>\n",
       "      <th>rhetorical_question</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3463</th>\n",
       "      <td>The population spike in Chicago in 9 months is...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3464</th>\n",
       "      <td>You'd think in the second to last English clas...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3465</th>\n",
       "      <td>I’m finally surfacing after a holiday to Scotl...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3466</th>\n",
       "      <td>Couldn't be prouder today. Well done to every ...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3467</th>\n",
       "      <td>Overheard as my 13 year old games with a frien...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  tweet  sarcastic  sarcasm  \\\n",
       "3463  The population spike in Chicago in 9 months is...          0      NaN   \n",
       "3464  You'd think in the second to last English clas...          0      NaN   \n",
       "3465  I’m finally surfacing after a holiday to Scotl...          0      NaN   \n",
       "3466  Couldn't be prouder today. Well done to every ...          0      NaN   \n",
       "3467  Overheard as my 13 year old games with a frien...          0      NaN   \n",
       "\n",
       "      irony  satire  understatement  overstatement  rhetorical_question  \n",
       "3463    NaN     NaN             NaN            NaN                  NaN  \n",
       "3464    NaN     NaN             NaN            NaN                  NaN  \n",
       "3465    NaN     NaN             NaN            NaN                  NaN  \n",
       "3466    NaN     NaN             NaN            NaN                  NaN  \n",
       "3467    NaN     NaN             NaN            NaN                  NaN  "
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dop NaN columns\n",
    "# tweets = tweets.dropna(any=[''])\n",
    "tweets = tweets.drop(tweets.columns[0], axis=1)\n",
    "\n",
    "tweets.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Binary Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>sarcastic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The only thing I got from college is a caffein...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I love it when professors draw a big question ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Remember the hundred emails from companies whe...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Today my pop-pop told me I was not “forced” to...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@VolphanCarol @littlewhitty @mysticalmanatee I...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               tweet  sarcastic\n",
       "0  The only thing I got from college is a caffein...          1\n",
       "1  I love it when professors draw a big question ...          1\n",
       "2  Remember the hundred emails from companies whe...          1\n",
       "3  Today my pop-pop told me I was not “forced” to...          1\n",
       "4  @VolphanCarol @littlewhitty @mysticalmanatee I...          1"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dropping unnecessary columns for binary classification\n",
    "tweets1 = tweets.drop(['sarcasm', 'irony', 'satire', 'understatement', 'overstatement', 'rhetorical_question'], axis=1)\n",
    "tweets1.dropna(how='any', inplace=True)\n",
    "tweets1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert label from float to int\n",
    "def transform_float_to_int(value):\n",
    "    return int(value)\n",
    "\n",
    "tweets1['sarcastic'] = tweets1.sarcastic.apply(transform_float_to_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split Tweet and Sarcastic Column\n",
    "X = tweets1['tweet']\n",
    "y = tweets1['sarcastic']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split Train & Test Data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=101, train_size=0.75)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apply Machine Learning Algorithm for Binary Classification Using BoW Row Count Ngram (Bigram & Trigram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BoW using Count Vertorizer using bigram\n",
    "# ngram range from 2 to 3 (bigram & trigram)\n",
    "cv = CountVectorizer(ngram_range=(2, 3), stop_words='english', binary='True')\n",
    "\n",
    "X_train_dtm = cv.fit_transform(X_train)\n",
    "X_test_dtm = cv.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      1.00      0.85       640\n",
      "           1       0.00      0.00      0.00       227\n",
      "\n",
      "    accuracy                           0.74       867\n",
      "   macro avg       0.37      0.50      0.42       867\n",
      "weighted avg       0.54      0.74      0.63       867\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Applying Logistic Regression\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train_dtm, y_train)\n",
    "y_pred = model.predict(X_test_dtm)\n",
    "print(classification_report(y_test, y_pred, zero_division=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      1.00      0.85       640\n",
      "           1       0.00      0.00      0.00       227\n",
      "\n",
      "    accuracy                           0.74       867\n",
      "   macro avg       0.37      0.50      0.42       867\n",
      "weighted avg       0.54      0.74      0.63       867\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Applying SVM\n",
    "model = SVC()\n",
    "model.fit(X_train_dtm, y_train)\n",
    "y_pred = model.predict(X_test_dtm)\n",
    "print(classification_report(y_test, y_pred, zero_division=0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      1.00      0.85       640\n",
      "           1       0.00      0.00      0.00       227\n",
      "\n",
      "    accuracy                           0.74       867\n",
      "   macro avg       0.37      0.50      0.42       867\n",
      "weighted avg       0.54      0.74      0.63       867\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Applying Random Forest Classifier\n",
    "model = RandomForestClassifier()\n",
    "model.fit(X_train_dtm, y_train)\n",
    "y_pred = model.predict(X_test_dtm)\n",
    "print(classification_report(y_test, y_pred, zero_division=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.27      0.40       640\n",
      "           1       0.27      0.76      0.40       227\n",
      "\n",
      "    accuracy                           0.40       867\n",
      "   macro avg       0.52      0.52      0.40       867\n",
      "weighted avg       0.63      0.40      0.40       867\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Applying Gaussian Naive Bayes Classifier\n",
    "model = GaussianNB()\n",
    "model.fit(X_train_dtm.toarray(), y_train)\n",
    "y_pred = model.predict(X_test_dtm.toarray())\n",
    "print(classification_report(y_test, y_pred, zero_division=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.93      0.82       640\n",
      "           1       0.26      0.07      0.11       227\n",
      "\n",
      "    accuracy                           0.70       867\n",
      "   macro avg       0.50      0.50      0.47       867\n",
      "weighted avg       0.61      0.70      0.64       867\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Applying Preceptron Classifier\n",
    "model = Perceptron(tol=1e-3, random_state=0)\n",
    "model.fit(X_train_dtm, y_train)\n",
    "y_pred = model.predict(X_test_dtm)\n",
    "print(classification_report(y_test, y_pred, zero_division=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apply Machine Learning Algorithm for Binary Classification Using BoW TFIDF Ngram (Bigram & Trigram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BoW using Count Vertorizer using bigram\n",
    "# ngram range from 2 to 3 (bigram & trigram)\n",
    "tfidf = TfidfVectorizer(ngram_range=(2, 3), stop_words='english', binary=True, use_idf=True)\n",
    "\n",
    "X_train_dtm = tfidf.fit_transform(X_train)\n",
    "X_test_dtm = tfidf.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      1.00      0.85       640\n",
      "           1       0.00      0.00      0.00       227\n",
      "\n",
      "    accuracy                           0.74       867\n",
      "   macro avg       0.37      0.50      0.42       867\n",
      "weighted avg       0.54      0.74      0.63       867\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Applying Logistic Regression\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train_dtm, y_train)\n",
    "y_pred = model.predict(X_test_dtm)\n",
    "print(classification_report(y_test, y_pred, zero_division=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      1.00      0.85       640\n",
      "           1       0.00      0.00      0.00       227\n",
      "\n",
      "    accuracy                           0.74       867\n",
      "   macro avg       0.37      0.50      0.42       867\n",
      "weighted avg       0.54      0.74      0.63       867\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Applying SVM\n",
    "model = SVC()\n",
    "model.fit(X_train_dtm, y_train)\n",
    "y_pred = model.predict(X_test_dtm)\n",
    "print(classification_report(y_test, y_pred, zero_division=0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      1.00      0.85       640\n",
      "           1       0.25      0.00      0.01       227\n",
      "\n",
      "    accuracy                           0.74       867\n",
      "   macro avg       0.49      0.50      0.43       867\n",
      "weighted avg       0.61      0.74      0.63       867\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Applying Random Forest Classifier\n",
    "model = RandomForestClassifier()\n",
    "model.fit(X_train_dtm, y_train)\n",
    "y_pred = model.predict(X_test_dtm)\n",
    "print(classification_report(y_test, y_pred, zero_division=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.27      0.40       640\n",
      "           1       0.27      0.76      0.40       227\n",
      "\n",
      "    accuracy                           0.40       867\n",
      "   macro avg       0.52      0.52      0.40       867\n",
      "weighted avg       0.63      0.40      0.40       867\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Applying Gaussian Naive Bayes Classifier\n",
    "model = GaussianNB()\n",
    "model.fit(X_train_dtm.toarray(), y_train)\n",
    "y_pred = model.predict(X_test_dtm.toarray())\n",
    "print(classification_report(y_test, y_pred, zero_division=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.90      0.81       640\n",
      "           1       0.24      0.09      0.13       227\n",
      "\n",
      "    accuracy                           0.69       867\n",
      "   macro avg       0.49      0.49      0.47       867\n",
      "weighted avg       0.61      0.69      0.63       867\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Applying Preceptron Classifier\n",
    "model = Perceptron(tol=1e-3, random_state=0)\n",
    "model.fit(X_train_dtm, y_train)\n",
    "y_pred = model.predict(X_test_dtm)\n",
    "print(classification_report(y_test, y_pred, zero_division=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing Data for multi class classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>sarcastic</th>\n",
       "      <th>sarcasm</th>\n",
       "      <th>irony</th>\n",
       "      <th>satire</th>\n",
       "      <th>understatement</th>\n",
       "      <th>overstatement</th>\n",
       "      <th>rhetorical_question</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The only thing I got from college is a caffein...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I love it when professors draw a big question ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Remember the hundred emails from companies whe...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Today my pop-pop told me I was not “forced” to...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@VolphanCarol @littlewhitty @mysticalmanatee I...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               tweet  sarcastic  sarcasm  \\\n",
       "0  The only thing I got from college is a caffein...          1      0.0   \n",
       "1  I love it when professors draw a big question ...          1      1.0   \n",
       "2  Remember the hundred emails from companies whe...          1      0.0   \n",
       "3  Today my pop-pop told me I was not “forced” to...          1      1.0   \n",
       "4  @VolphanCarol @littlewhitty @mysticalmanatee I...          1      1.0   \n",
       "\n",
       "   irony  satire  understatement  overstatement  rhetorical_question  \n",
       "0    1.0     0.0             0.0            0.0                  0.0  \n",
       "1    0.0     0.0             0.0            0.0                  0.0  \n",
       "2    1.0     0.0             0.0            0.0                  0.0  \n",
       "3    0.0     0.0             0.0            0.0                  0.0  \n",
       "4    0.0     0.0             0.0            0.0                  0.0  "
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_multi = tweets.copy()\n",
    "tweets_multi = tweets_multi[tweets.sarcastic == 1]\n",
    "tweets_multi.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_col_to_label(row):\n",
    "    if row.irony == 1.0:\n",
    "        return 'irony'\n",
    "    if row.satire == 1.0:\n",
    "        return 'satire';\n",
    "    if row.understatement == 1.0:\n",
    "        return 'understatement'\n",
    "    if row.overstatement == 1.0:\n",
    "        return 'overstatement'\n",
    "    if row.rhetorical_question == 1.0:\n",
    "        return 'rhetorical_question'\n",
    "    return 'Other'\n",
    "\n",
    "tweets_multi['label'] = tweets_multi.apply(lambda row: convert_col_to_label(row), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_multi = tweets_multi.drop(['sarcasm', 'sarcastic', 'irony', 'satire', 'understatement', 'overstatement', 'rhetorical_question'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "labelencoder = LabelEncoder()\n",
    "tweets_multi['label'] = labelencoder.fit_transform(tweets_multi['label'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apply Machine Learning Algorithm for Multi Class Classification Using BoW Row Count Ngram (Bigram & Trigram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tweets_multi['tweet']\n",
    "y = tweets_multi['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split Train & Test Data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=101, train_size=0.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BoW using Count Vertorizer using bigram\n",
    "# ngram range from 2 to 3 (bigram & trigram)\n",
    "cv = CountVectorizer(ngram_range=(2, 3), stop_words='english')\n",
    "\n",
    "X_train_dtm = cv.fit_transform(X_train)\n",
    "X_test_dtm = cv.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00        39\n",
      "           0       0.66      1.00      0.79       143\n",
      "           3       0.00      0.00      0.00        23\n",
      "           5       0.00      0.00      0.00         1\n",
      "           4       0.00      0.00      0.00         3\n",
      "           2       0.00      0.00      0.00         8\n",
      "\n",
      "    accuracy                           0.66       217\n",
      "   macro avg       0.11      0.17      0.13       217\n",
      "weighted avg       0.43      0.66      0.52       217\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Applying Logistic Regression\n",
    "model = LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
    "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
    "                   multi_class='ovr', n_jobs=None, penalty='l2',\n",
    "                   random_state=None, solver='liblinear', tol=0.0001, verbose=0,\n",
    "                   warm_start=False)\n",
    "model.fit(X_train_dtm, y_train)\n",
    "y_pred = model.predict(X_test_dtm)\n",
    "print(classification_report(y_test, y_pred, zero_division=0, labels=tweets_multi.label.unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00        39\n",
      "           0       0.66      1.00      0.79       143\n",
      "           3       0.00      0.00      0.00        23\n",
      "           5       0.00      0.00      0.00         1\n",
      "           4       0.00      0.00      0.00         3\n",
      "           2       0.00      0.00      0.00         8\n",
      "\n",
      "    accuracy                           0.66       217\n",
      "   macro avg       0.11      0.17      0.13       217\n",
      "weighted avg       0.43      0.66      0.52       217\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Applying SVM\n",
    "model = SVC(kernel='poly', C=1.0)\n",
    "model.fit(X_train_dtm, y_train)\n",
    "y_pred = model.predict(X_test_dtm)\n",
    "print(classification_report(y_test, y_pred, zero_division=0, labels=tweets_multi.label.unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00        39\n",
      "           0       0.66      1.00      0.79       143\n",
      "           3       0.00      0.00      0.00        23\n",
      "           5       0.00      0.00      0.00         1\n",
      "           4       0.00      0.00      0.00         3\n",
      "           2       0.00      0.00      0.00         8\n",
      "\n",
      "    accuracy                           0.66       217\n",
      "   macro avg       0.11      0.17      0.13       217\n",
      "weighted avg       0.43      0.66      0.52       217\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Applying Random Forest Classifier\n",
    "model = RandomForestClassifier(n_estimators = 10, max_depth=3, criterion = 'entropy')\n",
    "model.fit(X_train_dtm, y_train)\n",
    "y_pred = model.predict(X_test_dtm)\n",
    "print(classification_report(y_test, y_pred, zero_division=0, labels=tweets_multi.label.unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00        39\n",
      "           0       0.66      1.00      0.79       143\n",
      "           3       0.00      0.00      0.00        23\n",
      "           5       0.00      0.00      0.00         1\n",
      "           4       0.00      0.00      0.00         3\n",
      "           2       0.00      0.00      0.00         8\n",
      "\n",
      "    accuracy                           0.66       217\n",
      "   macro avg       0.11      0.17      0.13       217\n",
      "weighted avg       0.43      0.66      0.52       217\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Applying Multinomial Naive Bayes Classifier\n",
    "model = MultinomialNB()\n",
    "model.fit(X_train_dtm.toarray(), y_train)\n",
    "y_pred = model.predict(X_test_dtm.toarray())\n",
    "print(classification_report(y_test, y_pred, zero_division=0, labels=tweets_multi.label.unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.50      0.10      0.17        39\n",
      "           0       0.68      0.99      0.81       143\n",
      "           3       0.50      0.04      0.08        23\n",
      "           5       0.00      0.00      0.00         1\n",
      "           4       0.00      0.00      0.00         3\n",
      "           2       0.00      0.00      0.00         8\n",
      "\n",
      "    accuracy                           0.67       217\n",
      "   macro avg       0.28      0.19      0.18       217\n",
      "weighted avg       0.59      0.67      0.57       217\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Applying Preceptron Classifier\n",
    "model = Perceptron(tol=1e-3, random_state=10)\n",
    "model.fit(X_train_dtm, y_train)\n",
    "y_pred = model.predict(X_test_dtm)\n",
    "print(classification_report(y_test, y_pred, zero_division=0, labels=tweets_multi.label.unique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apply Machine Learning Algorithm for Multi Class Classification Using BoW TFIDF Ngram (Bigram & Trigram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BoW using TFIDF using bigram\n",
    "# ngram range from 2 to 3 (bigram & trigram)\n",
    "tfidf = TfidfVectorizer(ngram_range=(2, 3), stop_words='english', use_idf=True)\n",
    "\n",
    "X_train_dtm = tfidf.fit_transform(X_train)\n",
    "X_test_dtm = tfidf.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00        39\n",
      "           0       0.66      1.00      0.79       143\n",
      "           3       0.00      0.00      0.00        23\n",
      "           5       0.00      0.00      0.00         1\n",
      "           4       0.00      0.00      0.00         3\n",
      "           2       0.00      0.00      0.00         8\n",
      "\n",
      "    accuracy                           0.66       217\n",
      "   macro avg       0.11      0.17      0.13       217\n",
      "weighted avg       0.43      0.66      0.52       217\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Applying Logistic Regression\n",
    "model = LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
    "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
    "                   multi_class='ovr', n_jobs=None, penalty='l2',\n",
    "                   random_state=None, solver='liblinear', tol=0.0001, verbose=0,\n",
    "                   warm_start=False)\n",
    "model.fit(X_train_dtm, y_train)\n",
    "y_pred = model.predict(X_test_dtm)\n",
    "print(classification_report(y_test, y_pred, zero_division=0, labels=tweets_multi.label.unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00        39\n",
      "           0       0.66      1.00      0.79       143\n",
      "           3       0.00      0.00      0.00        23\n",
      "           5       0.00      0.00      0.00         1\n",
      "           4       0.00      0.00      0.00         3\n",
      "           2       0.00      0.00      0.00         8\n",
      "\n",
      "    accuracy                           0.66       217\n",
      "   macro avg       0.11      0.17      0.13       217\n",
      "weighted avg       0.43      0.66      0.52       217\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Applying SVM\n",
    "model = SVC(kernel='poly', C=1.0)\n",
    "model.fit(X_train_dtm, y_train)\n",
    "y_pred = model.predict(X_test_dtm)\n",
    "print(classification_report(y_test, y_pred, zero_division=0, labels=tweets_multi.label.unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00        39\n",
      "           0       0.66      1.00      0.79       143\n",
      "           3       0.00      0.00      0.00        23\n",
      "           5       0.00      0.00      0.00         1\n",
      "           4       0.00      0.00      0.00         3\n",
      "           2       0.00      0.00      0.00         8\n",
      "\n",
      "    accuracy                           0.66       217\n",
      "   macro avg       0.11      0.17      0.13       217\n",
      "weighted avg       0.43      0.66      0.52       217\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Applying Random Forest Classifier\n",
    "model = RandomForestClassifier(n_estimators = 10, max_depth=3, criterion = 'entropy')\n",
    "model.fit(X_train_dtm, y_train)\n",
    "y_pred = model.predict(X_test_dtm)\n",
    "print(classification_report(y_test, y_pred, zero_division=0, labels=tweets_multi.label.unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00        39\n",
      "           0       0.66      1.00      0.79       143\n",
      "           3       0.00      0.00      0.00        23\n",
      "           5       0.00      0.00      0.00         1\n",
      "           4       0.00      0.00      0.00         3\n",
      "           2       0.00      0.00      0.00         8\n",
      "\n",
      "    accuracy                           0.66       217\n",
      "   macro avg       0.11      0.17      0.13       217\n",
      "weighted avg       0.43      0.66      0.52       217\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Applying Multinomial Naive Bayes Classifier\n",
    "model = MultinomialNB()\n",
    "model.fit(X_train_dtm.toarray(), y_train)\n",
    "y_pred = model.predict(X_test_dtm.toarray())\n",
    "print(classification_report(y_test, y_pred, zero_division=0, labels=tweets_multi.label.unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.44      0.10      0.17        39\n",
      "           0       0.69      0.98      0.81       143\n",
      "           3       0.33      0.04      0.08        23\n",
      "           5       0.00      0.00      0.00         1\n",
      "           4       0.00      0.00      0.00         3\n",
      "           2       0.00      0.00      0.00         8\n",
      "\n",
      "    accuracy                           0.67       217\n",
      "   macro avg       0.24      0.19      0.18       217\n",
      "weighted avg       0.57      0.67      0.57       217\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Applying Preceptron Classifier\n",
    "model = Perceptron(tol=1e-3, random_state=10)\n",
    "model.fit(X_train_dtm, y_train)\n",
    "y_pred = model.predict(X_test_dtm)\n",
    "print(classification_report(y_test, y_pred, zero_division=0, labels=tweets_multi.label.unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5d681dc4c5cbd80cc618676dd6169611bafe3b7d10cc745436a35486ed14f444"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
