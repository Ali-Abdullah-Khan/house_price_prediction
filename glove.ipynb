{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import Perceptron\n",
    "from gensim.models import KeyedVectors\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.layers import LSTM, GRU, Dense, Embedding, Dropout, Bidirectional, InputLayer\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers.experimental.preprocessing import TextVectorization\n",
    "\n",
    "import nltk # import package for tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nltk.download('punkt') # download all spporting function /files for NLTK package\n",
    "# nltk.download('stopwords') #download Stopwords\n",
    "# nltk.download('tagsets')\n",
    "# nltk.help.upenn_tagset()# tagset documentation\n",
    "# nltk.download('wordnet')\n",
    "# nltk.download('averaged_perceptron_tagger')#lemmatization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from collections import defaultdict #Default Dictionary is imported from collections\n",
    "from nltk.corpus import wordnet as wn #the corpus reader wordnet is imported.\n",
    "from nltk.tag import pos_tag\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "from sklearn.preprocessing import scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>tweet</th>\n",
       "      <th>sarcastic</th>\n",
       "      <th>sarcasm</th>\n",
       "      <th>irony</th>\n",
       "      <th>satire</th>\n",
       "      <th>understatement</th>\n",
       "      <th>overstatement</th>\n",
       "      <th>rhetorical_question</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>The only thing I got from college is a caffein...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>I love it when professors draw a big question ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Remember the hundred emails from companies whe...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Today my pop-pop told me I was not “forced” to...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>@VolphanCarol @littlewhitty @mysticalmanatee I...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                              tweet  sarcastic  \\\n",
       "0           0  The only thing I got from college is a caffein...          1   \n",
       "1           1  I love it when professors draw a big question ...          1   \n",
       "2           2  Remember the hundred emails from companies whe...          1   \n",
       "3           3  Today my pop-pop told me I was not “forced” to...          1   \n",
       "4           4  @VolphanCarol @littlewhitty @mysticalmanatee I...          1   \n",
       "\n",
       "   sarcasm  irony  satire  understatement  overstatement  rhetorical_question  \n",
       "0      0.0    1.0     0.0             0.0            0.0                  0.0  \n",
       "1      1.0    0.0     0.0             0.0            0.0                  0.0  \n",
       "2      0.0    1.0     0.0             0.0            0.0                  0.0  \n",
       "3      1.0    0.0     0.0             0.0            0.0                  0.0  \n",
       "4      1.0    0.0     0.0             0.0            0.0                  0.0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets = pd.read_csv(\"sarcasm_dataset.csv\")\n",
    "\n",
    "tweets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>sarcastic</th>\n",
       "      <th>sarcasm</th>\n",
       "      <th>irony</th>\n",
       "      <th>satire</th>\n",
       "      <th>understatement</th>\n",
       "      <th>overstatement</th>\n",
       "      <th>rhetorical_question</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3463</th>\n",
       "      <td>The population spike in Chicago in 9 months is...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3464</th>\n",
       "      <td>You'd think in the second to last English clas...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3465</th>\n",
       "      <td>I’m finally surfacing after a holiday to Scotl...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3466</th>\n",
       "      <td>Couldn't be prouder today. Well done to every ...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3467</th>\n",
       "      <td>Overheard as my 13 year old games with a frien...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  tweet  sarcastic  sarcasm  \\\n",
       "3463  The population spike in Chicago in 9 months is...          0      NaN   \n",
       "3464  You'd think in the second to last English clas...          0      NaN   \n",
       "3465  I’m finally surfacing after a holiday to Scotl...          0      NaN   \n",
       "3466  Couldn't be prouder today. Well done to every ...          0      NaN   \n",
       "3467  Overheard as my 13 year old games with a frien...          0      NaN   \n",
       "\n",
       "      irony  satire  understatement  overstatement  rhetorical_question  \n",
       "3463    NaN     NaN             NaN            NaN                  NaN  \n",
       "3464    NaN     NaN             NaN            NaN                  NaN  \n",
       "3465    NaN     NaN             NaN            NaN                  NaN  \n",
       "3466    NaN     NaN             NaN            NaN                  NaN  \n",
       "3467    NaN     NaN             NaN            NaN                  NaN  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dop NaN columns\n",
    "tweets = tweets.drop(tweets.columns[0], axis=1)\n",
    "\n",
    "tweets.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>sarcastic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The only thing I got from college is a caffein...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I love it when professors draw a big question ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Remember the hundred emails from companies whe...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Today my pop-pop told me I was not “forced” to...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@VolphanCarol @littlewhitty @mysticalmanatee I...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               tweet  sarcastic\n",
       "0  The only thing I got from college is a caffein...          1\n",
       "1  I love it when professors draw a big question ...          1\n",
       "2  Remember the hundred emails from companies whe...          1\n",
       "3  Today my pop-pop told me I was not “forced” to...          1\n",
       "4  @VolphanCarol @littlewhitty @mysticalmanatee I...          1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dropping unnecessary columns for binary classification\n",
    "tweets1 = tweets.drop(['sarcasm', 'irony', 'satire', 'understatement', 'overstatement', 'rhetorical_question'], axis=1)\n",
    "tweets1.dropna(how='any', inplace=True)\n",
    "tweets1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert label from float to int\n",
    "def transform_float_to_int(value):\n",
    "    return int(value)\n",
    "\n",
    "tweets1['sarcastic'] = tweets1.sarcastic.apply(transform_float_to_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>sarcastic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The only thing I got from college is a caffein...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I love it when professors draw a big question ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Remember the hundred emails from companies whe...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Today my pop-pop told me I was not “forced” to...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@VolphanCarol @littlewhitty @mysticalmanatee I...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>@jimrossignol I choose to interpret it as \"XD\"...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Why would Alexa's recipe for Yorkshire pudding...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>someone hit me w a horse tranquilizer istg ive...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Loving season  of trump does America. Funniest...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Holly Arnold ??? Who #ImACeleb  #MBE nope not ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               tweet  sarcastic\n",
       "0  The only thing I got from college is a caffein...          1\n",
       "1  I love it when professors draw a big question ...          1\n",
       "2  Remember the hundred emails from companies whe...          1\n",
       "3  Today my pop-pop told me I was not “forced” to...          1\n",
       "4  @VolphanCarol @littlewhitty @mysticalmanatee I...          1\n",
       "5  @jimrossignol I choose to interpret it as \"XD\"...          1\n",
       "6  Why would Alexa's recipe for Yorkshire pudding...          1\n",
       "7  someone hit me w a horse tranquilizer istg ive...          1\n",
       "8  Loving season  of trump does America. Funniest...          1\n",
       "9  Holly Arnold ??? Who #ImACeleb  #MBE nope not ...          1"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Remove number\n",
    "import re # import all Regular expression functions\n",
    "tweets1['tweet']=[re.sub('\\d','', i)for i in tweets1['tweet']]\n",
    "tweets1.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>sarcastic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The only thing I got from college is a caffein...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I love it when professors draw a big question ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Remember the hundred emails from companies whe...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Today my pop pop told me I was not “forced” to...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>VolphanCarol  littlewhitty  mysticalmanatee I...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>jimrossignol I choose to interpret it as  XD ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Why would Alexa s recipe for Yorkshire pudding...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>someone hit me w a horse tranquilizer istg ive...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Loving season  of trump does America  Funniest...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Holly Arnold     Who  ImACeleb   MBE nope not ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               tweet  sarcastic\n",
       "0  The only thing I got from college is a caffein...          1\n",
       "1  I love it when professors draw a big question ...          1\n",
       "2  Remember the hundred emails from companies whe...          1\n",
       "3  Today my pop pop told me I was not “forced” to...          1\n",
       "4   VolphanCarol  littlewhitty  mysticalmanatee I...          1\n",
       "5   jimrossignol I choose to interpret it as  XD ...          1\n",
       "6  Why would Alexa s recipe for Yorkshire pudding...          1\n",
       "7  someone hit me w a horse tranquilizer istg ive...          1\n",
       "8  Loving season  of trump does America  Funniest...          1\n",
       "9  Holly Arnold     Who  ImACeleb   MBE nope not ...          1"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Replace punctuations with a white space\n",
    "import string\n",
    "tweets1['tweet']=[re.sub('[%s]' % re.escape(string.punctuation), ' ', i) for i in tweets1['tweet']]\n",
    "tweets1.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert into in lower case\n",
    "tweets1['tweet']=[i.lower() for i in tweets1['tweet']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>sarcastic</th>\n",
       "      <th>tweet_wt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>the only thing i got from college is a caffein...</td>\n",
       "      <td>1</td>\n",
       "      <td>[the, only, thing, i, got, from, college, is, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>i love it when professors draw a big question ...</td>\n",
       "      <td>1</td>\n",
       "      <td>[i, love, it, when, professors, draw, a, big, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>remember the hundred emails from companies whe...</td>\n",
       "      <td>1</td>\n",
       "      <td>[remember, the, hundred, emails, from, compani...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>today my pop pop told me i was not “forced” to...</td>\n",
       "      <td>1</td>\n",
       "      <td>[today, my, pop, pop, told, me, i, was, not, “...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>volphancarol  littlewhitty  mysticalmanatee i...</td>\n",
       "      <td>1</td>\n",
       "      <td>[volphancarol, littlewhitty, mysticalmanatee, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               tweet  sarcastic  \\\n",
       "0  the only thing i got from college is a caffein...          1   \n",
       "1  i love it when professors draw a big question ...          1   \n",
       "2  remember the hundred emails from companies whe...          1   \n",
       "3  today my pop pop told me i was not “forced” to...          1   \n",
       "4   volphancarol  littlewhitty  mysticalmanatee i...          1   \n",
       "\n",
       "                                            tweet_wt  \n",
       "0  [the, only, thing, i, got, from, college, is, ...  \n",
       "1  [i, love, it, when, professors, draw, a, big, ...  \n",
       "2  [remember, the, hundred, emails, from, compani...  \n",
       "3  [today, my, pop, pop, told, me, i, was, not, “...  \n",
       "4  [volphancarol, littlewhitty, mysticalmanatee, ...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets1['tweet_wt'] = [word_tokenize(i) for i in tweets1['tweet']]\n",
    "tweets1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>sarcastic</th>\n",
       "      <th>tweet_wt</th>\n",
       "      <th>tweet_SW</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>the only thing i got from college is a caffein...</td>\n",
       "      <td>1</td>\n",
       "      <td>[the, only, thing, i, got, from, college, is, ...</td>\n",
       "      <td>[thing, got, college, caffeine, addiction]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>i love it when professors draw a big question ...</td>\n",
       "      <td>1</td>\n",
       "      <td>[i, love, it, when, professors, draw, a, big, ...</td>\n",
       "      <td>[love, professors, draw, big, question, mark, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>remember the hundred emails from companies whe...</td>\n",
       "      <td>1</td>\n",
       "      <td>[remember, the, hundred, emails, from, compani...</td>\n",
       "      <td>[remember, hundred, emails, companies, covid, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>today my pop pop told me i was not “forced” to...</td>\n",
       "      <td>1</td>\n",
       "      <td>[today, my, pop, pop, told, me, i, was, not, “...</td>\n",
       "      <td>[today, pop, pop, told, “, forced, ”, go, coll...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>volphancarol  littlewhitty  mysticalmanatee i...</td>\n",
       "      <td>1</td>\n",
       "      <td>[volphancarol, littlewhitty, mysticalmanatee, ...</td>\n",
       "      <td>[volphancarol, littlewhitty, mysticalmanatee, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               tweet  sarcastic  \\\n",
       "0  the only thing i got from college is a caffein...          1   \n",
       "1  i love it when professors draw a big question ...          1   \n",
       "2  remember the hundred emails from companies whe...          1   \n",
       "3  today my pop pop told me i was not “forced” to...          1   \n",
       "4   volphancarol  littlewhitty  mysticalmanatee i...          1   \n",
       "\n",
       "                                            tweet_wt  \\\n",
       "0  [the, only, thing, i, got, from, college, is, ...   \n",
       "1  [i, love, it, when, professors, draw, a, big, ...   \n",
       "2  [remember, the, hundred, emails, from, compani...   \n",
       "3  [today, my, pop, pop, told, me, i, was, not, “...   \n",
       "4  [volphancarol, littlewhitty, mysticalmanatee, ...   \n",
       "\n",
       "                                            tweet_SW  \n",
       "0         [thing, got, college, caffeine, addiction]  \n",
       "1  [love, professors, draw, big, question, mark, ...  \n",
       "2  [remember, hundred, emails, companies, covid, ...  \n",
       "3  [today, pop, pop, told, “, forced, ”, go, coll...  \n",
       "4  [volphancarol, littlewhitty, mysticalmanatee, ...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#To show the stop words\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "#Remove All Stop Word\n",
    "tweets1['tweet_SW'] = [[i for i in j if not i in stop_words] for j in tweets1['tweet_wt']]# remove the word which is aviable in stopword libr\n",
    "tweets1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WordNetLemmatizer requires Pos tags to understand if the word is noun or verb or adjective etc. \n",
    "#By default it is set to Noun\n",
    "tag_map = defaultdict(lambda : wn.NOUN) #Dictionary is created where pos_tag (first letter) are the key values \n",
    "tag_map['J'] = wn.ADJ                   #whose values are mapped with the value \n",
    "tag_map['V'] = wn.VERB                  #from wordnet dictionary. We have taken the only first letter as we will use it later in the loop.\n",
    "tag_map['R'] = wn.ADV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>sarcastic</th>\n",
       "      <th>tweet_wt</th>\n",
       "      <th>tweet_SW</th>\n",
       "      <th>tweet_lemma</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>the only thing i got from college is a caffein...</td>\n",
       "      <td>1</td>\n",
       "      <td>[the, only, thing, i, got, from, college, is, ...</td>\n",
       "      <td>[thing, got, college, caffeine, addiction]</td>\n",
       "      <td>[thing, get, college, caffeine, addiction]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>i love it when professors draw a big question ...</td>\n",
       "      <td>1</td>\n",
       "      <td>[i, love, it, when, professors, draw, a, big, ...</td>\n",
       "      <td>[love, professors, draw, big, question, mark, ...</td>\n",
       "      <td>[love, professor, draw, big, question, mark, n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>remember the hundred emails from companies whe...</td>\n",
       "      <td>1</td>\n",
       "      <td>[remember, the, hundred, emails, from, compani...</td>\n",
       "      <td>[remember, hundred, emails, companies, covid, ...</td>\n",
       "      <td>[remember, hundred, email, company, covid, sta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>today my pop pop told me i was not “forced” to...</td>\n",
       "      <td>1</td>\n",
       "      <td>[today, my, pop, pop, told, me, i, was, not, “...</td>\n",
       "      <td>[today, pop, pop, told, “, forced, ”, go, coll...</td>\n",
       "      <td>[today, pop, pop, tell, “, force, ”, go, colle...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>volphancarol  littlewhitty  mysticalmanatee i...</td>\n",
       "      <td>1</td>\n",
       "      <td>[volphancarol, littlewhitty, mysticalmanatee, ...</td>\n",
       "      <td>[volphancarol, littlewhitty, mysticalmanatee, ...</td>\n",
       "      <td>[volphancarol, littlewhitty, mysticalmanatee, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               tweet  sarcastic  \\\n",
       "0  the only thing i got from college is a caffein...          1   \n",
       "1  i love it when professors draw a big question ...          1   \n",
       "2  remember the hundred emails from companies whe...          1   \n",
       "3  today my pop pop told me i was not “forced” to...          1   \n",
       "4   volphancarol  littlewhitty  mysticalmanatee i...          1   \n",
       "\n",
       "                                            tweet_wt  \\\n",
       "0  [the, only, thing, i, got, from, college, is, ...   \n",
       "1  [i, love, it, when, professors, draw, a, big, ...   \n",
       "2  [remember, the, hundred, emails, from, compani...   \n",
       "3  [today, my, pop, pop, told, me, i, was, not, “...   \n",
       "4  [volphancarol, littlewhitty, mysticalmanatee, ...   \n",
       "\n",
       "                                            tweet_SW  \\\n",
       "0         [thing, got, college, caffeine, addiction]   \n",
       "1  [love, professors, draw, big, question, mark, ...   \n",
       "2  [remember, hundred, emails, companies, covid, ...   \n",
       "3  [today, pop, pop, told, “, forced, ”, go, coll...   \n",
       "4  [volphancarol, littlewhitty, mysticalmanatee, ...   \n",
       "\n",
       "                                         tweet_lemma  \n",
       "0         [thing, get, college, caffeine, addiction]  \n",
       "1  [love, professor, draw, big, question, mark, n...  \n",
       "2  [remember, hundred, email, company, covid, sta...  \n",
       "3  [today, pop, pop, tell, “, force, ”, go, colle...  \n",
       "4  [volphancarol, littlewhitty, mysticalmanatee, ...  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "tweets1['tweet_lemma']=[[lemmatizer.lemmatize(word,tag_map[tag[0]]) for word ,tag in pos_tag(i)] for i in tweets1['tweet_SW']] \n",
    "tweets1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    " tweets1['tweet_clean']= tweets1['tweet_lemma'].apply(lambda x: ' '.join(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3463            population spike chicago month ridiculous\n",
       "3464    think second last english class year prof woul...\n",
       "3465    ’ finally surface holiday scotland difficult d...\n",
       "3466    prouder today well do every student get gcse m...\n",
       "3467    overheard year old game friend smell like tart...\n",
       "Name: tweet_clean, dtype: object"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets1['tweet_clean'].tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word Embedding Using Glove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.scripts.glove2word2vec import glove2word2vec\n",
    "from gensim.test.utils import datapath, get_tmpfile\n",
    "\n",
    "# glove_file = 'glove.6B.300d.txt'\n",
    "# tmp_file = get_tmpfile(\"./glove_word2vec.txt\")\n",
    "\n",
    "# _ = glove2word2vec('glove.6B.300d.txt', tmp_file)\n",
    "\n",
    "glove_embed = KeyedVectors.load_word2vec_format('glove.6B.300d.txt', binary=False, no_header=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Next we have to build word vectors for input text in order to average the value of all word vectors using the following function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Build word vector set by using the average value of all word vectors , then scale\n",
    "def buildWordVector(text, size):\n",
    "    vec = np.zeros(size).reshape((1, size)) #As word vectors are of zero length size value(i.e 300) \n",
    "    count = 0 # no. of words with a valid vector in the tweet\n",
    "    for word in text: #for each word in a tweet\n",
    "        try:\n",
    "            vec += glove_embed[word].reshape((1, size))\n",
    "            count += 1.\n",
    "        except KeyError:\n",
    "            continue\n",
    "    if count != 0:\n",
    "        vec /= count\n",
    "    return vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "Size = 300\n",
    "\n",
    "vecs = np.concatenate([buildWordVector(z, Size) for z in tweets1['tweet_lemma']])\n",
    "# print(\"Before Scaling:\",vecs[1:2])\n",
    "vecs = scale(vecs)\n",
    "# print(\"After Scaling:\",vecs[1:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimension of vector : (3467, 300)\n"
     ]
    }
   ],
   "source": [
    "print(\"Dimension of vector :\",vecs.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preceptron ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(vecs,tweets1['sarcastic'],test_size=0.25,random_state=342)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.84      0.81       648\n",
      "           1       0.39      0.30      0.34       219\n",
      "\n",
      "    accuracy                           0.70       867\n",
      "   macro avg       0.58      0.57      0.57       867\n",
      "weighted avg       0.68      0.70      0.69       867\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Applying Preceptron Classifier\n",
    "model = Perceptron(tol=1e-2, random_state=0, )\n",
    "model.fit(X_train, Y_train)\n",
    "Y_pred = model.predict(X_test)\n",
    "print(classification_report(Y_test, Y_pred, zero_division=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BiLSTM with 0.2 Dropout and 2 layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TextVectorization(max_tokens=20000, output_sequence_length=300)\n",
    "vectorizer.adapt(tweets1['tweet_clean'].to_numpy())\n",
    "vocab = vectorizer.get_vocabulary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "voc = vectorizer.get_vocabulary()\n",
    "word_index = dict(zip(voc, range(len(voc))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 6981 words (2148 misses)\n"
     ]
    }
   ],
   "source": [
    "num_tokens = len(voc) + 2\n",
    "embedding_dim = 300\n",
    "hits = 0\n",
    "misses = 0\n",
    "\n",
    "# Prepare embedding matrix\n",
    "embedding_matrix = np.zeros((num_tokens, embedding_dim))\n",
    "for word, i in word_index.items():\n",
    "    try:\n",
    "        embedding_vector = glove_embed.get_vector(word)\n",
    "        if embedding_vector is not None:\n",
    "            # Words not found in embedding index will be all-zeros.\n",
    "            # This includes the representation for \"padding\" and \"OOV\"\n",
    "            embedding_matrix[i] = embedding_vector\n",
    "            hits += 1\n",
    "        else:\n",
    "            misses += 1\n",
    "    except KeyError:\n",
    "        misses += 1\n",
    "print(\"Converted %d words (%d misses)\" % (hits, misses))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(tweets1['tweet_clean'],tweets1['sarcastic'],test_size=0.25,random_state=342)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = vectorizer(np.array([[s] for s in X_train])).numpy()\n",
    "X_test = vectorizer(np.array([[s] for s in X_test])).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, None, 300)         2739300   \n",
      "_________________________________________________________________\n",
      "bidirectional_2 (Bidirection (None, 600)               1442400   \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 600)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 601       \n",
      "=================================================================\n",
      "Total params: 4,182,301\n",
      "Trainable params: 1,443,001\n",
      "Non-trainable params: 2,739,300\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# LSTM Model with two layer and 0.2 dropout rate\n",
    "model = Sequential()\n",
    "model.add(InputLayer(input_shape=(None,)))\n",
    "model.add(Embedding(num_tokens, embedding_dim, embeddings_initializer=tf.keras.initializers.Constant(embedding_matrix), trainable=False))\n",
    "model.add(Bidirectional(LSTM(300, return_sequences=True)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Bidirectional(LSTM(300)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "model.build(X_train)\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "82/82 [==============================] - 116s 1s/step - loss: 0.5747 - accuracy: 0.7423 - val_loss: 0.5630 - val_accuracy: 0.7474\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fc8acc753d0>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 32\n",
    "\n",
    "model.fit(X_train, Y_train, batch_size=batch_size, epochs=1,\n",
    "          validation_data=(X_test, Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      1.00      0.86       648\n",
      "           1       0.00      0.00      0.00       219\n",
      "\n",
      "    accuracy                           0.75       867\n",
      "   macro avg       0.37      0.50      0.43       867\n",
      "weighted avg       0.56      0.75      0.64       867\n",
      "\n"
     ]
    }
   ],
   "source": [
    "preds = model.predict(X_test, verbose=0)\n",
    "predictions = [1 if x > 0.5 else 0 for x in preds]\n",
    "print(classification_report(Y_test, predictions, zero_division=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
